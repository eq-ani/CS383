{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3KijSLdDtfr"
      },
      "source": [
        "# Assignment 5: Introduction to Pytorch\n",
        "## PyTorch\n",
        "\n",
        "**PyTorch** is an open-source machine learning library for Python that is widely used for developing and training deep learning models.\n",
        "\n",
        "PyTorch provides two main features:\n",
        "\n",
        "1.  An n-dimensional **Tensor**, similar to NumPy but can run on GPUs.\n",
        "2.  Automatic differentiation for building and training neural networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_tzTvZujtuc"
      },
      "source": [
        "TODO: How many late days are you using for this assignment?\n",
        "Ans: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Sk7qzM0EGy-"
      },
      "source": [
        "## Section 1: PyTorch Tensors\n",
        "\n",
        "- These next few code blocks introduce PyTorch tensors, covering their creation from lists and NumPy arrays, initialization with random values, ones, and zeros, and key attributes like shape, datatype, and device placement.\n",
        "- Please fill out the None values in the following cells with the appropriate functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mRENraBbRgP"
      },
      "source": [
        "### Section 1.1 Creating Tensors\n",
        "\n",
        "##### Creating a Tensor from a List  \n",
        "PyTorch tensors are core to working with data and building models in PyTorch. They are important as they provide the foundation for efficient computation, especially for deep learning tasks. PyTorch tensors can be muti-dimensional and can be easily moved between GPU and CPU. To begin working with PyTorch, we will start by creating tensors.\n",
        "\n",
        "This cell imports the PyTorch library and initializes a 2D list. It includes a TODO to create a tensor from the list using `torch.tensor(data)`, but the assignment to `x_data` is currently set to `None`. The cell is intended to demonstrate creating a tensor from a Python list.  \n",
        "\n",
        "In the following section please update the **None** values with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "72_VWMUZDvLQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor from list:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the PyTorch library\n",
        "import torch\n",
        "# ### Creating Tensors\n",
        "data = [[1, 2], [3, 4]]\n",
        "# TODO: Create a tensor from a list and output the tensor\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"Tensor from list:\\n {x_data} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfuanlyFYQto"
      },
      "source": [
        "##### Creating a Tensor from a NumPy Array  \n",
        "Pytorch provides an easy way to convert NumPy objects to PyTorch Tensors. We will explore this in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5BBA_1RbGPky"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor from NumPy array:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]]) \n",
            "\n",
            "NumPy array from tensor:\n",
            " [[1 2]\n",
            " [3 4]] \n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "np_array = np.array(data)\n",
        "# TODO: Create a tensor from a NumPy array\n",
        "x_np = torch.from_numpy(np_array)\n",
        "print(f\"Tensor from NumPy array:\\n {x_np} \\n\")\n",
        "\n",
        "# TODO: Convert the tensor back to a NumPy array\n",
        "x_np_back = x_np.numpy()\n",
        "print(f\"NumPy array from tensor:\\n {x_np_back} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhuya3r7Yua0"
      },
      "source": [
        "##### Creating Tensors with Specific Values  \n",
        "This cell includes TODOs for creating tensors with specific properties:  \n",
        "- `x_ones`: A tensor of the same shape as `x_data`, filled with ones, retaining its properties.  \n",
        "- `x_rand`: A tensor of the same shape as `x_data`, filled with random values between 0 and 1, overriding its datatype.  \n",
        "- `rand_tensor`: A randomly initialized tensor with a specified shape `(2,3)`.  \n",
        "- `ones_tensor`: A tensor of shape `(2,3)` filled with ones.  \n",
        "- `zeros_tensor`: A tensor of shape `(2,3)` filled with zeros.  \n",
        "\n",
        "##### Tensor Attributes  \n",
        "The last part of this cell creates a random tensor of shape `(3,4)` and prints its attributes: shape, datatype, and the device it is stored on.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rstUFSZuGVwG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ones Tensor: \n",
            " tensor([[1, 1],\n",
            "        [1, 1]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.4931, 0.9397],\n",
            "        [0.2389, 0.3784]]) \n",
            "\n",
            "Random Tensor: \n",
            " tensor([[0.6914, 0.7416, 0.9328],\n",
            "        [0.6985, 0.5679, 0.7611]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "# TODO: Create a tensor of same dimensions as x_data with ones in place\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "#TODO: Creates a tensor of same dimensions as x_data with random values between 0 and 1\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
        "\n",
        "# Create a tensor with specified shape\n",
        "shape = (2,3)\n",
        "\n",
        "# TODO: Fill out the following None values\n",
        "rand_tensor = torch.rand(shape)        # A tensor of shape (2,3) with random values\n",
        "ones_tensor = torch.ones(shape)        # A tensor of shape (2,3) with ones\n",
        "zeros_tensor = torch.zeros(shape)      # A tensor of shape (2,3) with zeros\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")\n",
        "\n",
        "print()\n",
        "#### Tensor Attributes\n",
        "tensor = torch.rand(3,4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3wrp1HzbAXc"
      },
      "source": [
        "### Section 1.2 Moving Tensors from CPU to GPU\n",
        "One great benefit of PyTorch is that it enables us to easily use GPUs. In deep learning, we often use very large tensors with parallelizable operations. The architecture of GPU can accelerate these operation, allowing more efficient learning. In this section, we will learn how to move tensors to GPU.  This section has no TODOs and is for your information.\n",
        "\n",
        "Note: This code block will give different outputs depending on your access to a GPU.\n",
        "\n",
        "The cell output displays what output you would get if you run this cell using a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "t5Xdy7L6Gwr2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is not available, using CPU.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The output of this cell will be different depending on if your machine has access to a GPU\n",
        "# Observe what happens when running it in your current enviornment\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # Use the first available GPU\n",
        "    print(\"GPU is available!\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available, using CPU.\")\n",
        "print()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  tensor = torch.rand(3,4)\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\") #By default, device is cpu\n",
        "  print('You are not using GPU yet!')\n",
        "  print()\n",
        "  tensor = tensor.to(device)\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")\n",
        "  print('Congrats, you are using GPU!')\n",
        "print()\n",
        "\n",
        "# Common Error\n",
        "if torch.cuda.is_available():\n",
        "    try:\n",
        "        y_cpu = torch.randn(3,4)\n",
        "        result = tensor + y_cpu # Error! Tensors on different devices\n",
        "    except RuntimeError as e:\n",
        "        print(\"Error:\", e)\n",
        "        print(\"Remember: Move both tensors to the same device to perform operations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkZvB3PAb6UT"
      },
      "source": [
        "### Section 1.3 Tensor Operations\n",
        "\n",
        "Tensor operations in PyTorch include a variety of element-wise and matrix operations such as addition, subtraction, multiplication, and division. Common operations include:  \n",
        "\n",
        "- **Element-wise Operations**: Addition (`+`), subtraction (`-`), multiplication (`*`), and division (`/`).  \n",
        "- **Matrix Operations**: Matrix multiplication (`torch.matmul()` or `@` operator), transposition (`tensor.T`), and inversion.  \n",
        "- **Reduction Operations**: Summation (`torch.sum()`), mean (`torch.mean()`), max/min (`torch.max()` / `torch.min()`).  \n",
        "- **Reshaping**: Changing tensor dimensions using `torch.reshape()`, `torch.view()`, or `torch.permute()`.  \n",
        "- **Concatenation and Stacking**: `torch.cat()` for joining along a dimension, `torch.stack()` for stacking along a new dimension.  \n",
        "- **In-place Operations**: Operations ending in `_` (e.g., `tensor.add_()`) modify the tensor directly.  \n",
        "\n",
        "### TODO: In the following section please update the **None** values with your answer in the subsequent codeblocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vUOVI2BPJbWm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First row:  tensor([1., 1., 1., 1.])\n",
            "First column:  tensor([1., 1., 1., 1.])\n",
            "Last column: tensor([1., 1., 1., 1.])\n",
            "Updated tensor: tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "# ### Tensor Operations\n",
        "\n",
        "# TODO: Standard numpy-like indexing and slicing:\n",
        "tensor = torch.ones(4, 4)\n",
        "\n",
        "# TODO: print the first row of the tensor\n",
        "first_row = tensor[0]\n",
        "print('First row: ', first_row)\n",
        "\n",
        "# TODO: print the first column of the tensor\n",
        "first_column = tensor[:, 0]\n",
        "print('First column: ', first_column)\n",
        "\n",
        "# TODO: print the first column of the tensor\n",
        "last_column = tensor[:, -1]\n",
        "print('Last column:', last_column)\n",
        "\n",
        "# TODO: Update the tensor so that index 1 column is all zeros and print the tensor\n",
        "tensor[:, 1] = 0\n",
        "print('Updated tensor:', tensor )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7oxsQ6IieUqA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sum: 21\n",
            "Mean: 3.5\n",
            "Max: 6\n",
            "Min: 1\n"
          ]
        }
      ],
      "source": [
        "# Reduction Operations\n",
        "\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "# Summation\n",
        "tensor_sum = torch.sum(tensor) # TODO: Compute Sum of all elements in tensor\n",
        "print(f\"Sum: {tensor_sum}\")\n",
        "\n",
        "# Mean\n",
        "tensor_mean = torch.mean(tensor.float())  # TODO: Compute mean of all elements in tensor. Note: Use .float() for mean\n",
        "print(f\"Mean: {tensor_mean}\")\n",
        "\n",
        "# Max/Min\n",
        "tensor_max = torch.max(tensor) # TODO: Find Max element in tensor\n",
        "tensor_min = torch.min(tensor) # TODO: Find Min element in tensor\n",
        "print(f\"Max: {tensor_max}\")\n",
        "print(f\"Min: {tensor_min}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZKj3Oq3hciS_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tensor shape: torch.Size([4, 4])\n",
            "Reshaped tensor shape: torch.Size([16])\n",
            "Reshaped tensor shape: torch.Size([2, 8])\n",
            "Original tensor shape: torch.Size([2, 3, 4])\n",
            "Permuted tensor shape: torch.Size([4, 2, 3])\n"
          ]
        }
      ],
      "source": [
        "# Reshaping\n",
        "\n",
        "x = torch.randn(4, 4)\n",
        "print(\"Original tensor shape:\", x.shape)\n",
        "y = x.view(-1)  # TODO: Reshape to a 1D tensor\n",
        "print(\"Reshaped tensor shape:\", y.shape)\n",
        "\n",
        "z = x.view(2, 8)  # TODO: Reshape to a 2x8 tensor\n",
        "print(\"Reshaped tensor shape:\", z.shape)\n",
        "\n",
        "\n",
        "# Permute (reorders dimensions)\n",
        "x = torch.randn(2, 3, 4)\n",
        "x_perm = x.permute(2, 0, 1) # TODO: Swap dimensions in order 2, 0, 1\n",
        "print(\"Original tensor shape:\", x.shape)\n",
        "print(\"Permuted tensor shape:\", x_perm.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hceRsbDvJy6r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Row Concatenated Tensors: tensor([[0.8044, 0.5604, 0.6205, 0.7005],\n",
            "        [0.0639, 0.6574, 0.2682, 0.8794],\n",
            "        [0.5498, 0.3874, 0.9864, 0.9959],\n",
            "        [0.5169, 0.7226, 0.3739, 0.3882],\n",
            "        [0.1452, 0.9068, 0.5340, 0.6604],\n",
            "        [0.0987, 0.7109, 0.7348, 0.7892],\n",
            "        [0.6161, 0.4473, 0.6619, 0.0025],\n",
            "        [0.4711, 0.6278, 0.4431, 0.7606]])\n",
            "Column Concatenated Tensors: tensor([[0.8044, 0.5604, 0.6205, 0.7005, 0.1452, 0.9068, 0.5340, 0.6604],\n",
            "        [0.0639, 0.6574, 0.2682, 0.8794, 0.0987, 0.7109, 0.7348, 0.7892],\n",
            "        [0.5498, 0.3874, 0.9864, 0.9959, 0.6161, 0.4473, 0.6619, 0.0025],\n",
            "        [0.5169, 0.7226, 0.3739, 0.3882, 0.4711, 0.6278, 0.4431, 0.7606]])\n",
            "tensor([[[0.8044, 0.5604, 0.6205, 0.7005],\n",
            "         [0.0639, 0.6574, 0.2682, 0.8794],\n",
            "         [0.5498, 0.3874, 0.9864, 0.9959],\n",
            "         [0.5169, 0.7226, 0.3739, 0.3882]],\n",
            "\n",
            "        [[0.1452, 0.9068, 0.5340, 0.6604],\n",
            "         [0.0987, 0.7109, 0.7348, 0.7892],\n",
            "         [0.6161, 0.4473, 0.6619, 0.0025],\n",
            "         [0.4711, 0.6278, 0.4431, 0.7606]],\n",
            "\n",
            "        [[0.8971, 0.2183, 0.1685, 0.9506],\n",
            "         [0.3268, 0.7807, 0.6663, 0.6602],\n",
            "         [0.8457, 0.1084, 0.1565, 0.6654],\n",
            "         [0.7818, 0.8225, 0.2671, 0.0510]]])\n"
          ]
        }
      ],
      "source": [
        "tensor_one = torch.rand(4, 4)\n",
        "tensor_two = torch.rand(4, 4)\n",
        "# TODO: Concatenate tensor_one and tensor_two row wise\n",
        "row_concatenated_tensor = torch.cat((tensor_one, tensor_two), dim=0)\n",
        "print('Row Concatenated Tensors:', row_concatenated_tensor)\n",
        "\n",
        "# TODO: Concatenate tensor_one and tensor_two column wise\n",
        "col_concatenated_tensor = torch.cat((tensor_one, tensor_two), dim=1)\n",
        "print('Column Concatenated Tensors:', col_concatenated_tensor)\n",
        "\n",
        "tensor_three = torch.rand(4, 4)\n",
        "# TODO: Stack tensors one, two and three along the default dimension (dim=0)\n",
        "stacked_tensor = torch.stack((tensor_one, tensor_two, tensor_three))\n",
        "\n",
        "print(stacked_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "60CmbBGmb0gj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "In-place operations\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]]) \n",
            "\n",
            "Added five to  all values of tensor tensor([[6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [6., 6., 6., 6.]])\n",
            "Subtract five to  all values of tensor tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n"
          ]
        }
      ],
      "source": [
        "#In-place operations\n",
        "tensor = torch.ones(4, 4)\n",
        "print()\n",
        "print('In-place operations')\n",
        "print(tensor, \"\\n\")\n",
        "\n",
        "tensor = torch.ones(4,4)\n",
        "# TODO: Add 5 to all values of the\n",
        "tensor.add_(5)\n",
        "print('Added five to  all values of tensor', tensor)\n",
        "\n",
        "# TODO: Subtract 5 to all values of the\n",
        "tensor.sub_(5)\n",
        "print('Subtract five to  all values of tensor', tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r8qxH-uyGaC4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Element wise multiplication: tensor([[0.1403, 0.5049, 0.2692, 0.0509],\n",
            "        [0.4591, 0.2156, 0.0291, 0.1975],\n",
            "        [0.4077, 0.0019, 0.1293, 0.1911],\n",
            "        [0.8498, 0.2428, 0.5478, 0.4254]])\n",
            "\n",
            "Dot product tensor: tensor([[1.1317, 0.5752, 0.7560, 1.0208],\n",
            "        [1.2092, 1.0166, 0.6877, 0.7118],\n",
            "        [1.7161, 1.0893, 1.0050, 1.1623],\n",
            "        [1.9919, 1.2616, 1.2346, 1.4481]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Multiplying tensors\n",
        "\n",
        "# TODO: Given two tensors, do an element wise multiplication\n",
        "# Hint: There is more than one way to do this\n",
        "tensor_one = torch.rand(4, 4)\n",
        "tensor_two = torch.rand(4, 4)\n",
        "\n",
        "element_wise_tensor = tensor_one * tensor_two\n",
        "print(\"Element wise multiplication:\", element_wise_tensor)\n",
        "print()\n",
        "\n",
        "# TODO: Compute the dot product of the two tensors\n",
        "# Hint: There is more than one way to do this\n",
        "dot_product_tensor = torch.matmul(tensor_one, tensor_two)\n",
        "print(\"Dot product tensor:\", dot_product_tensor)\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K85ZVnKXcnPG"
      },
      "source": [
        "### Section 1.4 Broadcasting\n",
        "Broadcasting in PyTorch is a useful feature that lets you perform operations on tensors of incompatible shapes without manually reshaping them. PyTorch automatically expands smaller tensors so their shapes are compatible for element-wise operations.\n",
        "\n",
        "You can read the details of these rules here: https://pytorch.org/docs/stable/notes/broadcasting.html\n",
        "\n",
        "\n",
        " In general you never need broadcasting as you can always be explicit with your tensor shapes. At first, broadcasting can feel like arbitrary rules but as you write more PyTorch you'll start to find them convienent particularly when working with training batches.\n",
        "\n",
        " Below we show some examples of broadcasting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iE8djsysaUgz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Broadcasting example 1:\n",
            " tensor([[11, 12],\n",
            "        [13, 14]])\n",
            "\n",
            "tensor([[11, 22],\n",
            "        [13, 24]])\n",
            "Broadcasting example 2:\n",
            " tensor([[11, 22],\n",
            "        [13, 24]])\n",
            "\n",
            "Broadcasting example 3:\n",
            " tensor([[10, 20, 30],\n",
            "        [20, 40, 60],\n",
            "        [30, 60, 90]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Broadcasting\n",
        "import torch\n",
        "# Example 1: Adding a scalar to a tensor\n",
        "tensor = torch.tensor([[1, 2], [3, 4]])  # shape (2, 2)\n",
        "scalar = torch.tensor(10)               # shape ()\n",
        "\n",
        "result = tensor + scalar  # Broadcasting scalar to shape (2, 2)\n",
        "# result: [[11, 12],\n",
        "#          [13, 14]]\n",
        "print(f\"Broadcasting example 1:\\n {result}\\n\")\n",
        "\n",
        "# Example 2: Adding a vector to a matrix (1D + 2D Tensor)\n",
        "a = torch.tensor([[1, 2], [3, 4]])  # shape (2, 2)\n",
        "b = torch.tensor([10, 20])         # shape (2,)\n",
        "\n",
        "result = a + b  # b is broadcast to shape (2, 2)\n",
        "print(result)\n",
        "# Output:\n",
        "# tensor([[11, 22],\n",
        "#         [13, 24]])\n",
        "print(f\"Broadcasting example 2:\\n {result}\\n\")\n",
        "\n",
        "# Example 3 — Column Vector + Matrix\n",
        "a = torch.tensor([[1], [2], [3]])  # shape (3, 1)\n",
        "b = torch.tensor([[10, 20, 30]])   # shape (1, 3)\n",
        "\n",
        "result = a * b  # a broadcast to (3, 3), b broadcast to (3, 3)\n",
        "print(f\"Broadcasting example 3:\\n {result}\\n\")\n",
        "# Output:\n",
        "# tensor([[10, 20, 30],\n",
        "#         [20, 40, 60],\n",
        "#         [30, 60, 90]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tF-ehnUq5Fyt"
      },
      "outputs": [],
      "source": [
        "#Examples 4 - Mismatched Dimensions\n",
        "#a = torch.ones((2, 3))\n",
        "#b = torch.ones((3, 2))\n",
        "\n",
        "#result = a + b\n",
        "#print(f\"Broadcasting example 4:\\n {result}\\n\") # Will give a runtime error\n",
        "#\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygoOUZyx1Q82"
      },
      "source": [
        "### TODO: Please answer the following questions.\n",
        "\n",
        "1) Predict the shape:\n",
        "\n",
        "    a = torch.ones((3, 1))\n",
        "    b = torch.ones((1, 4))\n",
        "    result = a + b\n",
        "\n",
        "Ans: (3, 4)\n",
        "\n",
        "2) Predict the shape:\n",
        "\n",
        "    a = torch.ones((2, 3))\n",
        "    b = torch.ones((2, 1))\n",
        "    result = a + b\n",
        "Ans: (2, 3)\n",
        "\n",
        "3) What is the output?\n",
        "\n",
        "    a = torch.tensor([[1], [2], [3]])  # shape (3, 1)\n",
        "    b = torch.tensor([10, 20])         # shape (2,)\n",
        "    result = a + b\n",
        "\n",
        "Ans: tensor([[11, 21], [12, 22], [13, 23]])\n",
        "\n",
        "4) Will the following code run? Please explain why or why not.\n",
        "    \n",
        "    \n",
        "    a = torch.ones((2, 2))\n",
        "    b = torch.ones((3, 1))\n",
        "\n",
        "    result = a + b\n",
        "\n",
        "Ans: No, it is a runtime error because (2, 2) and (3, 1) are incompatible for\n",
        "broadcasting. Since their outer dimensions differ, there is no way to align them. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NrFCWLuPSqR"
      },
      "source": [
        "## Section 2: Automatic Differentiaion with Logistic Regression\n",
        "\n",
        "In this section, we'll use logistic regression as an example to explain the entire flow of building and training a model. Logistic Regression was introduced in class, but we will now explore how it more detail. Specifically, we will build the model from scratch using PyTorch modules, and train it on our data using automatic differentiation. This process invloves implement implementing the model's forward pass, selecting the appropriate loss and optimizer components, and then writing a training loop to optimize the model relative to our dataset.\n",
        "\n",
        "**Note: There are no TODOs for Section 2 but it is critical you read, run, and understand this code or in order to understand what you need for Section 3 and future assignments.**\n",
        "\n",
        "### Iris Dataset\n",
        "\n",
        "To train our logistic regression model we will use a classic machine learning dataset - the Iris dataset. It containes 150 instances of iris flowers categorized by three species: Setosa, Versicolor, and Virginica. Each flower is describes by four numerical features:\n",
        "\n",
        "\n",
        "*   Sepal length (cm)\n",
        "*   Sepal width (cm)\n",
        "*   Petal length (cm)\n",
        "*   Petal width (cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KAvnSFsLRieZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "csv_path = \"iris.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xqmZhpalo23"
      },
      "source": [
        "### Section 2.1 `Dataset` and `DataLoader`\n",
        "\n",
        "In deep learning, handling large datasets efficiently is crucial. During training, doing gradient calculations on an entire large dataset can be time consuming. So a better way to handle large datasets is to divide samples into smaller batches and do the calculations individually. PyTorch provides `Dataset` and `DataLoader` to streamline this process:\n",
        "\n",
        "- **`Dataset` Class**: Helps organize and preprocess data by defining how to load samples. It enables transformations, label encoding, and normalization before passing data to a model.\n",
        "- **`DataLoader` Class**: Manages batch loading, shuffling, and parallel processing, optimizing data feeding into the training loop.\n",
        "\n",
        "This structured approach organizes your code, improves performance, and ensures smooth model training, especially for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-0xknXOypejw"
      },
      "outputs": [],
      "source": [
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Initialize the IrisDataset.\n",
        "\n",
        "        Args:\n",
        "            X (dtype -- numpy.ndarray): Features (sepal length, sepal width, petal length, petal width)\n",
        "            y (dtype -- numpy.ndarray): Target (species)\n",
        "        \"\"\"\n",
        "        # We first convert the features ad labels to pytorch tensors\n",
        "        # We convert feature data (X) to float32 data type as PyTorch models (like nn.Linear) expect this format.\n",
        "        # We convert target data (y) to int64 data type to ensure compatibility with PyTorch's loss functions.\n",
        "        self.x = torch.from_numpy(X.astype(np.float32))\n",
        "        self.y = torch.from_numpy(y.astype(np.int64))\n",
        "\n",
        "        # Store the number of samples in the dataset\n",
        "        self.n_samples = X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Allows for indexing. For example, we can do dataset[0]\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        # Allows us to call len(dataset)\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6HIgIP9bP0P"
      },
      "source": [
        "We will now load the dataset, preprocess it and create instances of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pbSVlY8ga6Ts"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: (120, 4), Testing set: (30, 4)\n"
          ]
        }
      ],
      "source": [
        "# Define the column names for the dataset\n",
        "column_names = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\", \"Species\"]\n",
        "\n",
        "# Load the data from the CSV file (above cells) into a Pandas DataFrame\n",
        "data = pd.read_csv(csv_path, names=column_names, header=0)\n",
        "\n",
        "# Encode the species target (categorical data) into numerical values\n",
        "# 0 -> Iris-setosa\n",
        "# 1 -> Iris-setosa\n",
        "# 2 -> Iris-virginica\n",
        "label_encoder = LabelEncoder()\n",
        "data[\"Species\"] = label_encoder.fit_transform(data[\"Species\"])\n",
        "\n",
        "# Seperate out the columns into features (all columns except the last one) and target (the last column)\n",
        "features = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
        "\n",
        "# Split dataset into features (X) and target (y)\n",
        "X = data[features].values  # Features\n",
        "y = data[\"Species\"].values   # Target\n",
        "y = y.flatten() # This ensures that out targets are a 1D array -- our loss function will require this!\n",
        "\n",
        "# Split dataset into training and testing sets using train_test_split -- We are using 20% of the samples as test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9OFw_XxTrW2K"
      },
      "outputs": [],
      "source": [
        "# Create datasets\n",
        "train_dataset = IrisDataset(X_train, y_train)\n",
        "test_dataset = IrisDataset(X_test, y_test)\n",
        "\n",
        "# Create DataLoader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEClxYsGf4tF"
      },
      "source": [
        "### Section 2.2 Create a LogisticRegression Module\n",
        "\n",
        "Logistic regression is a simple yet effective classification algorithm that applies a linear transformation to input features and uses a softmax activation to predict class probabilities. To help you get started, we are providing demo/sample code for a logistic regression implementation. This will give you a basic structure to build upon as you develop your understanding of logistic regression.\n",
        "\n",
        "In this section, we will create a simple logistic regression class using PyTorch's nn.Linear layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "C6JS7MgdgTse"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Logistic Regression Model\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        # Define a single fully connected layer with a bias (linear transformation)\n",
        "        # This maps input features (input_dim) to output classes (num_classes)\n",
        "        self.linear = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Forward pass: Apply the linear transformation to input data\n",
        "        # Note: We do not use an activation function here because\n",
        "        # PyTorch's CrossEntropyLoss automatically applies softmax\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL7vtXodofjI"
      },
      "source": [
        "### Section 2.3 Create Our Model and Components\n",
        "\n",
        "Now that we have defined our logistic regression class, we need to train it on our dataset. PyTorch provides many pre-built implementations of common deep learning components to make this relatively easy to do. However, a lot is happening behind the scenes so let's break it down."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hFMiGST5kU08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression(\n",
            "  (linear): Linear(in_features=4, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Get the number of features and classes\n",
        "input_dim = 4  # Number of features -- You can automatically determine from the data using `X_train.shape[1]`\n",
        "num_classes = 3  # Number of categories in dataset -- You can automatically determine from the data using `len(np.unique(y))`\n",
        "\n",
        "# Initialize model, loss function, and optimizer\n",
        "model = LogisticRegression(input_dim, num_classes)  # Create an instance of our logistic regression model\n",
        "criterion = nn.CrossEntropyLoss()  # Loss function for multi-class classification\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)  # Stochastic Gradient Descent optimizer with a learning rate of 0.01\n",
        "\n",
        "# Let's see what model we initialized\n",
        "print(model)  # This prints the structure of our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQRVSwtB85vw"
      },
      "source": [
        "Above, we initialize an instance of the logistic regression model we just created. We also define a loss/objective function to measure how well the model is performing and an optimizer to update the model's parameters based on gradients computed during backpropagation.\n",
        "\n",
        "We use a PyTorch built-in for the loss function and optimizer which are similiar to the squared error loss and gradient descent alogirthms we discussed in lecture. Cross Entropy is a loss with better properties for classification and will make our training more smooth and consistent. While \"Stochastic\" Gradient Descent is the gradient descent we've seen but implies a single training datapoint is used instead of all the datapoints (more on this later). In practice, it's common to use these built-ins instead of writing them from scratch, but PyTorch makes it relatively easy to extend and define your own if you want to create a custom loss function or optimization algorithm. Notice how we take the `parameters()` of the model and provide them to our optimizer. This tells the optimization algorithm which tensors need to updated on each iteration of our training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSwiacl6NK4o"
      },
      "source": [
        "### Section 2.4 The Training Loop\n",
        "\n",
        "**Note: If you've been skimming the prior sections be sure to slow down and understand this one in detail. This content is incredibly important and likely to show up on an exam.**\n",
        "\n",
        "Now, we will see the power of PyTorch with *automatic differentiation.* In the background PyTorch tracks all of the operations performed on any tensor that you create and builds a computational graph which tracks the influence of each operation on downstream values. This tracking occurs *across* variable assignments so the graph is reflective of your entire program from input tensor to final output tensor. In deep learning, the final tensor is usually your computed loss for a subset (batch) of the training data. Then with a single call to the `backward()` routine **the entire backpropagation algorithm is run** to compute the gradients for the computation graph. Below, we put everything together: the model, training components, dataloader, etc. Read through the code and run it, then we will break it down.\n",
        "\n",
        "A few terms will be helpful before we move forward:\n",
        "\n",
        "* **epoch**: One complete forward and backward pass of all samples in the training set.\n",
        "\n",
        "* **batch_size**: The number of training samples in a single forward and backward pass.\n",
        "\n",
        "* **number of iterations**: The total number of passes, where each pass processes batch_size number of samples.\n",
        "\n",
        "For example, if we have 100 samples and set `batch_size = 20`, then `100 / 20 = 5` iterations are needed for one complete epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "IbVSwajKhWA6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/100], Loss: 0.6924\n",
            "Epoch [20/100], Loss: 0.4679\n",
            "Epoch [30/100], Loss: 0.3282\n",
            "Epoch [40/100], Loss: 0.4497\n",
            "Epoch [50/100], Loss: 0.6465\n",
            "Epoch [60/100], Loss: 0.3977\n",
            "Epoch [70/100], Loss: 0.4993\n",
            "Epoch [80/100], Loss: 0.2586\n",
            "Epoch [90/100], Loss: 0.4750\n",
            "Epoch [100/100], Loss: 0.3565\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 100  # Number of times the entire dataset is passed through the model\n",
        "for epoch in range(num_epochs):\n",
        "    # We loop over train_loader to process batches efficiently\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        # Forward pass: Compute model predictions\n",
        "        outputs = model(inputs)  # Pass inputs through the model\n",
        "        loss = criterion(outputs, labels)  # Compute loss between predictions and actual labels\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()  # Reset gradients to zero before backpropagation\n",
        "        loss.backward()  # Compute gradients of the loss with respect to model parameters\n",
        "        optimizer.step()  # Update model parameters using computed gradients\n",
        "\n",
        "    # Print loss every 10 epochs to monitor training progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')  # Print epoch number and current loss value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6js-HaZ10atF"
      },
      "source": [
        "The first few lines are boilerplate which set up our training loop and call our `Dataloader` that we created earlier to get a *batch* of the data. In class, we showed how each iteration of gradient descent updated the model parameters for all the training datapoints. Often in practice, our machine does not have enough memory to do this (particularly for big models and large datasets). So we instead *estimate* the true gradient with a subset of the data (batch) and update our parameters incrementally. Confusingly, this is referred to as **mini-batch gradident descent** in contrast to using *all* training datapoints, which is **batch gradient descent.** There are theoretical implications of doing one versus the other which is why people distinguish, so to summarize:\n",
        "\n",
        "| Term                       | Description                                                                 |\n",
        "|----------------------------|-----------------------------------------------------------------------------|\n",
        "| Batch Gradient Descent     | Uses **all** training data to compute the gradient and update parameters.   |\n",
        "| Mini-Batch Gradient Descent| Uses a **subset** (mini-batch) of the training data to estimate the gradient. |\n",
        "| Stochastic Gradient Descent| Uses **one** training example at a time to estimate the gradient.           |\n",
        "\n",
        "The next couple lines call our model on the training batch and compute the loss for this batch. The three lines that follow are crucial:\n",
        "\n",
        "```python\n",
        "optimizer.zero_grad()\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "The first line does nothing on the first iteration, but on subsequent iterations clears out the gradients computed on the previous batch. The next line performs backpropagation to compute the gradients for the current batch which are accumulated on each of the models' individual parameters. In the next line the optimizer computes the updates for each of these parameters relative to the gradients and applies them to each parameter of our model (recall we connected them earlier when we initialized the optimizer).\n",
        "\n",
        "In summary, the training process involves repeatedly passing the training data through the model, computing the loss, calculating gradients, and updating the model parameters. This training loop iterates over the dataset multiple times, adjusting the model's parameters to minimize the loss. By following this structure, you can train a logistic regression model to classify iris flowers based on their features. Each epoch represents a full pass through the dataset, and the optimizer updates the weights in a way that reduces the classification error over time. This iterative process helps the model learn the optimal weights for making predictions relative to the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS1uLn60nQO9"
      },
      "source": [
        "# Section 3: Creating a Multi-Layer Perceptron Using the Titanic dataset\n",
        "In the previous sections, we reviewed the basics of PyTorch from creating tensors to creating a basic model. In this section, we will ask you to put it all together. We will ask you train a multi-layer perceptron to perform classification on the titanic dataset. We will ask you to do some data cleaning, create a model, train and test the model, do some experimentation and present the results.\n",
        "\n",
        "\n",
        "## Titanic Dataset\n",
        "The Titanic dataset is a dataset containing information of the passengers of the RMS Titanic, a British passanger ship which famously sunk upon hitting an iceberg. The dataset can be used for binary classification, predicting whether a passenger survived or not.  The dataset includes demographic, socio-economic, and onboard information such as:\n",
        "\n",
        "\n",
        "- Survived (Target Variable): 0 = No, 1 = Yes\n",
        "- Pclass (Passenger Class): 1st, 2nd, or 3rd class\n",
        "- Sex: Male or Female\n",
        "- Age: Passenger's age in years\n",
        "- SibSp: Number of siblings/spouses aboard\n",
        "- Parch: Number of parents/children aboard\n",
        "- Fare: Ticket fare price\n",
        "- Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "DzKPNapBVW-v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "TlscqXNBd17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhg1dBCFtatI"
      },
      "source": [
        "### Section 3.1: Process data for modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "U0vmFWcXspVj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: (712, 7), Testing set: (179, 7)\n"
          ]
        }
      ],
      "source": [
        "# TODO : Handle missing values for \"Age\" and \"Embarked\"\n",
        "df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].median())\n",
        "df[\"Embarked\"] = df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0])\n",
        "# TODO: Encode categorical features \"Sex\" and \"Embarked\"\n",
        "# Hint: Use LabelEncoder (check imports)\n",
        "label_encoder_sex = LabelEncoder()\n",
        "label_encoder_embarked = LabelEncoder()\n",
        "df[\"Sex\"] = label_encoder_sex.fit_transform(df[\"Sex\"])\n",
        "df[\"Embarked\"] = label_encoder_embarked.fit_transform(df[\"Embarked\"])\n",
        "# TODO: Select features and target\n",
        "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
        "X = df[features].values\n",
        "y = df[\"Survived\"].values\n",
        "# TODO: Normalize numerical features in X\n",
        "# Hint: Use StandardScaler()\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, Testing set: {X_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErqCEhnbtk3q"
      },
      "source": [
        "### Section 3.2 Create a Dataset Class with the Previous Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iyzpNdidVN9L"
      },
      "outputs": [],
      "source": [
        "class TitanicDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        # TODO: initialize X, y as tensors\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.X[index], self.y[index]\n",
        "\n",
        "# TODO: Instantiate the dataset classes\n",
        "train_dataset = TitanicDataset(X_train, y_train)\n",
        "test_dataset = TitanicDataset(X_test, y_test)\n",
        "\n",
        "# TODO: Create Dataloaders using the datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmQVqXHkuS2q"
      },
      "source": [
        "### Section 3.3 Create a MLP class\n",
        "In this section we will create a multi-layer perceptron with the following specification.\n",
        "We will have a total of three fully connected layers.\n",
        "\n",
        "\n",
        "1.   Fully Connected Layer of size (7, 64) followed by ReLU\n",
        "2.   Full Connected Layer of Size (64, 32) followed by ReLU\n",
        "3. Full Connected Layer of Size (32, 1) followed by Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "dnAEHi5QVp0k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TitanicMLP(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=7, out_features=64, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
            "    (5): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class TitanicMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TitanicMLP, self).__init__()\n",
        "        # TODO: Define Layers\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(7, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "    \n",
        "model = TitanicMLP()\n",
        "print(model)\n",
        "\n",
        "# TODO: Move the model to GPU if possible\n",
        "# I have a mac, would be possible but requires quite a bit of additional setup\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfFKYNlj2Bhg"
      },
      "source": [
        "### Section 3.4 : Writing a training and testing loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0yRL8RJoVyxR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.6525\n",
            "Epoch [2/20], Loss: 0.5731\n",
            "Epoch [3/20], Loss: 0.5066\n",
            "Epoch [4/20], Loss: 0.4468\n",
            "Epoch [5/20], Loss: 0.4417\n",
            "Epoch [6/20], Loss: 0.4217\n",
            "Epoch [7/20], Loss: 0.4221\n",
            "Epoch [8/20], Loss: 0.4269\n",
            "Epoch [9/20], Loss: 0.4197\n",
            "Epoch [10/20], Loss: 0.4082\n",
            "Epoch [11/20], Loss: 0.4139\n",
            "Epoch [12/20], Loss: 0.4048\n",
            "Epoch [13/20], Loss: 0.4002\n",
            "Epoch [14/20], Loss: 0.4000\n",
            "Epoch [15/20], Loss: 0.4027\n",
            "Epoch [16/20], Loss: 0.3849\n",
            "Epoch [17/20], Loss: 0.3957\n",
            "Epoch [18/20], Loss: 0.3887\n",
            "Epoch [19/20], Loss: 0.3958\n",
            "Epoch [20/20], Loss: 0.3841\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAVkZJREFUeJzt3Qd4VFXeBvA3vQApJKRDEmroHYyAoEAoFrCCDUVEpawFXcu6gmBhVxRdXT8RlaKrAroKKkqVIlICobdAgCQESE8ISUghme/5nzCzCUkgCZPcmbnv73muM3Pnzs05M4nzcso9dgaDwQAiIiIiHbHXugBEREREDY0BiIiIiHSHAYiIiIh0hwGIiIiIdIcBiIiIiHSHAYiIiIh0hwGIiIiIdIcBiIiIiHSHAYiIiIh0hwGIiKr06KOPIiwsrE6vff3112FnZ2f2MhERmQsDEJGVkWBRk23jxo3Qa3Br3LgxrMWPP/6IESNGwNfXF87OzggKCsJ9992H33//XeuiEdk0O64FRmRd/vOf/1R4/OWXX2Lt2rX46quvKuwfOnQo/P396/xziouLUVpaChcXl1q/9tKlS2pzdXWFFgHo+++/R25uLiyZ/K/3sccew6JFi9C9e3fcc889CAgIwLlz51QoiomJwZ9//okbb7xR66IS2SRHrQtARLXz0EMPVXi8fft2FYCu3H+l/Px8uLu71/jnODk51bmMjo6OaqPqvffeeyr8PPvss5g7d26FLsNXX31VBVpzvIcStAoKCuDm5nbd5yKyJewCI7JBgwYNQqdOnVQrwk033aSCz9/+9jf13IoVK3DrrbeqrhZp3WnVqhXeeOMNlJSUXHUMUHx8vPqSfvfddzF//nz1Onl97969sXPnzmuOAZLHU6dOxfLly1XZ5LUdO3bEqlWrKpVfuu969eqlWpDk53z66admH1f03XffoWfPnioYSPeTBMgzZ85UOCY5ORnjx49HSEiIKm9gYCBGjRql3gujXbt2YdiwYeoccq7w8HDVsnM1Fy9exOzZsxEREaHez6rq9fDDD6NPnz7qfnV1lwAl+8uXRz6z2267DatXr1bvoZRJ3j95z2+++eZK55BWvuDgYNUCVX7fBx98oD4f+QykJfHJJ59EVlbWNd9XImvBf6IR2aiMjAw1tmTs2LHqy93YHSZfmjJGZtq0aepWxppMnz4dOTk5mDNnzjXP+8033+DChQvqC1G+fN955x3cddddOHny5DVbjbZs2YIffvgBkydPRpMmTfDhhx/i7rvvRmJiInx8fNQxe/bswfDhw1XYmDlzpgpms2bNQrNmzcz0zpS9BxJsJLxJEElJScG//vUv1eUkP9/Ly0sdJ2U7dOgQ/vKXv6hgkZqaqlrbpLzGx1FRUapsL7/8snqdhBGp47Xeh8zMTNX64+DgAHOLjY3F/fffrz6jiRMnol27dhgzZowKUhLqpKutfFnOnj2rfk+M5HXG9+jpp5/GqVOn8O9//1u9N/IeXU/rIJHFkDFARGS9pkyZIuP4KuwbOHCg2jdv3rxKx+fn51fa9+STTxrc3d0NBQUFpn2PPPKIITQ01PT41KlT6pw+Pj6GzMxM0/4VK1ao/T///LNp34wZMyqVSR47Ozsb4uLiTPv27dun9n/00Uemfbfffrsqy5kzZ0z7jh8/bnB0dKx0zqpIuRs1alTt80VFRQY/Pz9Dp06dDBcvXjTt/+WXX9T5p0+frh5nZWWpx3PmzKn2XD/++KM6ZufOnYba+Ne//qVeJ6+viareT7Fw4UK1Xz4bI/nMZN+qVasqHBsbG1vpvRaTJ082NG7c2PR78ccff6jjvv766wrHyfmq2k9krdgFRmSjpMtG/gV/pfJjQaQlJz09HQMGDFBjhI4ePXrN80pLgre3t+mxvFZIC9C1DBkyRHVpGXXp0gUeHh6m10prz7p16zB69GjVRWfUunVr1ZplDtJlJS030gpVfpC2dAtKl9TKlStN75PMypLuuOq6fowtRb/88osaNF5T0tompBWsPkg3nHTLlde2bVt069YNS5cuNe2T91sGjN9+++2m3wvpGvT09FSD6OV3w7hJd6G0GG7YsKFeykzU0BiAiGyUjOuQL/ArSZfOnXfeqb7kJHxI941xAPX58+eved4WLVpUeGwMQzUZH3Lla42vN75WgomMj5HAc6Wq9tVFQkKCupVuoStJADI+LwHyn//8J3777TfVfShjqaS7T7qQjAYOHKi6yaSrTsYAyfighQsXorCw8KplkPfdGEDrKwBVF16lC8s41knCnbznst/o+PHj6vfAz89P/W6U32RmnRxPZAsYgIhsVFWzfrKzs9WX9r59+9S4mp9//lmNaZEveuPg12upbsxKTa6ocT2v1YKM0Tl27JgaJyStRa+99hrat2+vxsIIGQMlLSjbtm1TA7wlWMgAaGktudo0fAla4sCBAzUqR3WDv68cuG5U3YwvCTryXksrj1i2bJkKwjLmykh+ByT8yO9FVZv83hDZAgYgIh2Rf/HL4GgZ4PrMM8+o2ULSLVW+S0tL8sUrQSMuLq7Sc1Xtq4vQ0FDTQOEryT7j80bSZff8889jzZo1OHjwIIqKitQU9vJuuOEGvPXWW6p77euvv1atbEuWLKm2DP3791fv+bffflttiCnP+PlIgC3P2FpVm5YhmVkm3WBynSYZrC3djeWv9ST1ld+Rfv36qd+NK7euXbvW6mcSWSoGICIdMbbAlG9xkS/0//u//4OllE++ZGWqvMxMKh9+pCvKHGRquAStefPmVeiqkvMfOXJEjQUSMiZKrp9TnoQDGbdjfJ103V3ZeiXjbMTVusHksgQvvfSS+nlyW1ULmFzwMjo62vRzxebNm03P5+XlYfHixbWuv7QCybWjFixYoMb2lO/+EnIVagllcmmEK0loujKEEVkrToMn0hG5qrC0JjzyyCNqerN0rcgF9yypC0qmaktri7RATJo0SX0ZyxRsuY7N3r17a3QOGZD85ptvVtrftGlTNfhZuvxkgLh0B8p0ceM0eJna/txzz6ljpetr8ODBKhB06NBBXZRQrtAsxxqnjEsAkfAoY6okpMiYns8++0yN8Rk5cuRVy/jXv/5VtRRJa5IMLDZeCVrGGEkAlPCzdetWdaxMtZfxUxMmTFCvk6AoAUbG5ciU/NqQ+rzwwgtqk/dDAmd58p7INHjp9pP3W362THuXsUHSdSbvU/lrBhFZLa2noRFR/UyD79ixY5XH//nnn4YbbrjB4ObmZggKCjK8+OKLhtWrV6tzbNiw4ZrT4KuaFi77Zar2tabBS1mvJD9DflZ569evN3Tv3l1Nm2/VqpXh888/Nzz//PMGV1fXa74fci75WVVtci6jpUuXqp/h4uJiaNq0qeHBBx80JCUlmZ5PT09X5Y2IiFDT6j09PQ19+/Y1LFu2zHTM7t27Dffff7+hRYsW6jwyvf62224z7Nq1y1BT33//vSEqKkqVQab6BwYGGsaMGWPYuHFjheNiYmLUz5f3RH7e3Llzq50Gf+utt171Z/br10+97vHHH6/2mPnz5xt69uypfk+aNGli6Ny5s/pdOXv2bI3rRmTJuBYYEVkFGasiLSbSEkFEdL04BoiILI5MhS9PQs+vv/6qlvggIjIHtgARkcWRZTBkLbKWLVuqmU6ffPKJGlQs08/btGmjdfGIyAZwEDQRWRy5Lo1MEZcBwTJFOzIyEm+//TbDDxGZDVuAiIiISHc4BoiIiIh0hwGIiIiIdIdjgKoga+HIVWjliq/VrcFDRERElkVG9cgFSYOCgmBvf/U2HgagKkj4ad68udbFICIiojo4ffo0QkJCrnoMA1AVpOXH+AbKJe1tlSwXIEsOGC91b+v0VF/W1Tbpqa56qy/rah45OTmqAcP4PX41DEBVMHZ7Sfix9QAkizJKHW39D05v9WVdbZOe6qq3+rKu5lWT4SscBE1ERES6wwBEREREusMARERERLrDAERERES6wwBEREREusMARERERLrDAERERES6wwBEREREusMARERERLrDAERERES6wwBEREREusMARERERLrDANSADAYDEjPycTb7otZFISIi0jXNA9DHH3+MsLAwuLq6om/fvoiOjr7q8dnZ2ZgyZQoCAwPh4uKCtm3b4tdffzU9//rrr6tVYMtvERERsARvrTyCm+ZswKKt8VoXhYiISNcctfzhS5cuxbRp0zBv3jwVfj744AMMGzYMsbGx8PPzq3R8UVERhg4dqp77/vvvERwcjISEBHh5eVU4rmPHjli3bp3psaOjptU06RDkoW6jT2VqXRQiIiJd0zQZzJ07FxMnTsT48ePVYwlCK1euxIIFC/Dyyy9XOl72Z2ZmYuvWrXByclL7pPXoShJ4AgICYGl6hzVVtwfPnEd+0SW4O1tGMCMiItIbzb6BpTUnJiYGr7zyimmfvb09hgwZgm3btlX5mp9++gmRkZGqC2zFihVo1qwZHnjgAbz00ktwcHAwHXf8+HEEBQWpbjU5fvbs2WjRokW1ZSksLFSbUU5OjrotLi5Wm7n4N3ZEgIcLknMKsetUOiJb+kBLxrqZs46WTE/1ZV1tk57qqrf6sq7mUZtz2hlkZK4Gzp49q7qwpDVHQorRiy++iE2bNmHHjh2VXiNjeeLj4/Hggw9i8uTJiIuLU7dPP/00ZsyYoY757bffkJubi3bt2uHcuXOYOXMmzpw5g4MHD6JJkyZVlkXGDclxV/rmm2/g7u5u1novPmaP3Rn2GB5SghHNNXnriYiIbFJ+fr5qGDl//jw8PMqGnVTHqvpgSktL1fif+fPnqxafnj17qnAzZ84cUwAaMWKE6fguXbqosUWhoaFYtmwZJkyYUOV5pRVKxiKVbwFq3rw5oqKirvkG1laW72ns/vkIzjs3w8iRvaAlScpr165V46qMXYq2TE/1ZV1tk57qqrf6sq7mYezBqQnNApCvr68KMSkpKRX2y+Pqxu/IzC95s8p3d7Vv3x7JycmqS83Z2bnSa2SAtMwUk9ai6shsMtmuJD/L3B9OZKtmAI5g7+nzgL0DnBw0n4hXL/W0ZHqqL+tqm/RUV73Vl3W9PrU5n2bfvhJWpAVn/fr1FVp45HH5LrHy+vXrp4KMHGd07NgxFYyqCj9CusNOnDihjrEEbfwaw8vdCReLS9RgaCIiImp4mjY/SLfTZ599hsWLF+PIkSOYNGkS8vLyTLPCxo0bV2GQtDwvs8CeeeYZFXxkxtjbb7+tBkUbvfDCC2oMkYwVkvFFd955p2oxuv/++2EJ7O3t0Cu0bDbYznhOhyciItKCpmOAxowZg7S0NEyfPl11Y3Xr1g2rVq2Cv7+/ej4xMVHNDDOScTmrV6/Gc889p8b3yCBqCUMyC8woKSlJhZ2MjAw1S6x///7Yvn27um8p+oR7Y92RFESfysITN2ldGiIiIv3RfBD01KlT1VaVjRs3Vton3WMSaKqzZMkSWDrj9YB2JWSitNSgWoWIiIio4Wg/AleHOgV7ws3JAdn5xTiemqt1cYiIiHSHAUgDMvOre4uy5TuiOQ6IiIiowTEAaaRP+OWB0FwXjIiIqMExAGmkT9j/ZoJpdDFuIiIi3WIA0kj3Ft5wtLfDufMFSMq6qHVxiIiIdIUBSCNuzg5qMLSIZjcYERFRg2IAsoRxQBwITURE1KAYgCzgekCcCUZERNSwGIA01DvMW92eTMtDem6h1sUhIiLSDQYgDXm5O6OdfxN1fxdbgYiIiBoMA5DGeoeXtQLJumBERETUMBiALGYcUIbWRSEiItINBiALmQl2+GwOLhQUa10cIiIiXWAA0ligpxtCvN1QagB2J2ZrXRwiIiJdYACyAFwXjIiIqGExAFnQumC8HhAREVHDYACyAL0vtwDtPZ2NwkslWheHiIjI5jEAWYCWvo3g29gZRZdKsT/pvNbFISIisnkMQBbAzs4OvUIvd4NxHBAREVG9YwCyEFwYlYiIqOEwAFlYAIqJz0KJzIknIiKiesMAZCHaB3qgsYsjLhRewtHkHK2LQ0REZNMYgCyEg70deoSWrQvG6wERERHVLwYgC9In7PLCqBwHREREVK8YgCxxYdRTWTAYOA6IiIiovjAAWZCuzb3g7GCP9NxCxGfka10cIiIim8UAZEFcnRzQtbmnus9xQERERPWHAchSu8E4DoiIiKjeMABZ6LpgvCAiERFR/WEAsjA9Q71hZwckZOQjJadA6+IQERHZJAYgC+Ph6oT2AR7qPtcFIyIiqh8MQBaI64IRERHVLwYgCw5AbAEiIiKqHwxAFjwTLDblAs5fLNa6OERERDaHAcgCNWvignDfRpCLQccksBWIiIjI3BiALFTvy+uC7WA3GBERkdkxAFl4NxivCE1ERGR+DEAWqm+4j7o9cOY8CopLtC4OERGRTWEAslDNm7rB38MFxSUG7EnM1ro4RERENoUByELZ2dn9rxuM1wMiIiIyKwYgC8YLIhIREdUPBiALZmwBiknIwqWSUq2LQ0REZDMYgCxYO/8m8HB1RH5RCQ6dzdG6OERERDaDAciC2dtzHBAREVF9YACycL25LhgREZHZMQBZOGML0K6ELBhkbQwiIiK6bgxAFq5zsCdcneyRmVeEE2m5WheHiIjIJjAAWThnR3t0a+6l7nNdMCIiIvNgALICfS4vi8F1wYiIiMyDAcgK9DHNBMvSuihEREQ2gQHICnRv4QUHezucyb6oNiIiIrLyAPTxxx8jLCwMrq6u6Nu3L6Kjo696fHZ2NqZMmYLAwEC4uLigbdu2+PXXX6/rnJaukYsjOgV5qPvsBiMiIrLyALR06VJMmzYNM2bMwO7du9G1a1cMGzYMqampVR5fVFSEoUOHIj4+Ht9//z1iY2Px2WefITg4uM7ntLbp8NG8ICIREZF1B6C5c+di4sSJGD9+PDp06IB58+bB3d0dCxYsqPJ42Z+ZmYnly5ejX79+qpVn4MCBKuTU9ZzWghdEJCIisoEAJK05MTExGDJkyP8KY2+vHm/btq3K1/z000+IjIxUXWD+/v7o1KkT3n77bZSUlNT5nNbWAhSXmquuCURERER15wiNpKenq+AiQaY8eXz06NEqX3Py5En8/vvvePDBB9W4n7i4OEyePBnFxcWqy6su5xSFhYVqM8rJKVt4VM4rmyVo4myH1s0aIS4tD9vj0jC0g991n9NYN0upY33TU31ZV9ukp7rqrb6sq3nU5pyaBaC6KC0thZ+fH+bPnw8HBwf07NkTZ86cwZw5c1QAqqvZs2dj5syZlfavWbNGdZ9ZCj97e8TBHss27kZxfKnZzrt27VroiZ7qy7raJj3VVW/1ZV2vT35+vuUHIF9fXxViUlJSKuyXxwEBAVW+RmZ+OTk5qdcZtW/fHsnJyar7qy7nFK+88ooaOF2+Bah58+aIioqCh0fZ7CtLULzvHLZ+fwCZ9l4YOfKG6z9fcbH6BZSB5fK+2jo91Zd1tU16qqve6su6moexB8eiA5Czs7NqwVm/fj1Gjx5tauGRx1OnTq3yNTLw+ZtvvlHHydgecezYMRWM5HyitucUMp1etivJB2NJv4iRrZup20PnLqCo1E5NjzcHS6tnfdNTfVlX26Snuuqtvqzr9anN+TSdBSatLjKNffHixThy5AgmTZqEvLw8NYNLjBs3TrXOGMnzMgvsmWeeUcFn5cqVahC0DIqu6TmtWbCXm9pKSg3YncirQhMREdWVpmOAxowZg7S0NEyfPl11Y3Xr1g2rVq0yDWJOTEw0tfQI6ZZavXo1nnvuOXTp0kVd/0fC0EsvvVTjc1q7PuFN8eOeM+qCiAPalLUIERERUe1oPghauqaq657auHFjpX0yDX779u11Pqe1k+nwEoB4QUQiIiIrXgqDaqdPuLe63ZOYjaJL5psJRkREpCcMQFamVbPGaNrIGYWXSnHgzHmti0NERGSVGICsjJ2dHXqFlrUC7WQ3GBERUZ0wAFnpQGjBdcGIiIjqhgHIigPQrvhMlJYatC4OERGR1WEAskIdAj3QyNkBOQWXEJtyQeviEBERWR0GICvk6GCPHhwHREREVGcMQFZ8PSDBcUBERES1xwBk5QFIWoAMBo4DIiIiqg0GICvVvYUXnBzskJJTiMTMfK2LQ0REZFUYgKyUq5MDuoR4qfvsBiMiIqodBiAb6QYjIiKimmMAsoF1wXbGZ2ldFCIiIqvCAGTFeoY2hZ0dcCo9D6kXCrQuDhERkdVgALJinm5OaOffRN3fxVYgIiKiGmMAsnJ9uS4YERFRrTEAWbneDEBERES1xgBk5fpcngl2JDkHOQXFWheHiIjIKjAAWTk/D1eE+rhDLgYdk8BxQERERDXBAGRL1wNiNxgREVGNMADZUDcYxwERERHVDAOQDehzeSD0/qTzKCgu0bo4REREFo8ByAbIGKBmTVxQVFKKfaeztS4OERGRxWMAsgF2dnambjCuC0ZERHRtDEA2ondY2bpg0bwiNBER0TUxANnYBRF3J2ThUkmp1sUhIiKyaAxANiIiwANNXByRW3gJR85d0Lo4REREFo0ByEY42NuZWoH+PJGudXGIiIgsGgOQDbmpja+63RibqnVRiIiILBoDkA0Z1M5P3e6Kz8IFrgtGRERULQYgGxLm2whhPu64VGrAn3EZWheHiIjIYjEA2Wgr0KZj7AYjIiKqDgOQjRnYrpm63RibBoMsEU9ERESVMADZmMiWPnBxtMe58wU4lpKrdXGIiIgsEgOQjXF1csANLX3Ufc4GIyIiqhoDkA0aVK4bjIiIiCpjALLl6fAJmerK0ERERFQRA5ANCvdthFAfdxSXyHR4XhWaiIjoSgxANmpQW3aDERERVYcByNavBxSbyunwREREV2AAslEyE8zZ0R5nzxfgeCqnwxMREZXHAGSj3Jw5HZ6IiKg6DEA2jOOAiIiIqsYApIPrAe2M53R4IiKi8hiAbHw6fIumZdPht53g6vBERERGDEA2zM7OrtxVoTkOiIiIyIgBSEfLYnA6PBERURkGIBsX2dJXTYc/k30RJ9I4HZ6IiEgwAOlgOnzf8KbqPmeDERERlWEA0tFVoRmAiIiIyjAA6WgcUPSpTORxOjwREREDkB609G2E5k3dUFRSyunwRERElhKAPv74Y4SFhcHV1RV9+/ZFdHR0tccuWrRITe8uv8nrynv00UcrHTN8+HDoejp828vdYMc4HZ6IiEjzALR06VJMmzYNM2bMwO7du9G1a1cMGzYMqanVf1F7eHjg3Llzpi0hIaHSMRJ4yh/z7bffQs84HZ6IiMiCAtDcuXMxceJEjB8/Hh06dMC8efPg7u6OBQsWXLVFIyAgwLT5+/tXOsbFxaXCMd7e3tCzyFY+cHawR1KWTIfP07o4REREmnLU8ocXFRUhJiYGr7zyimmfvb09hgwZgm3btlX7utzcXISGhqK0tBQ9evTA22+/jY4dO1Y4ZuPGjfDz81PB55ZbbsGbb74JH5+y1dGvVFhYqDajnJwcdVtcXKw2W+BkB/QO88afJzLw+5FkhHqHmupmK3W8Fj3Vl3W1TXqqq97qy7qaR23OaWfQsD/k7NmzCA4OxtatWxEZGWna/+KLL2LTpk3YsWNHpddIMDp+/Di6dOmC8+fP491338XmzZtx6NAhhISEqGOWLFmiWpHCw8Nx4sQJ/O1vf0Pjxo3Vax0cHCqd8/XXX8fMmTMr7f/mm2/UeWzFhrN2WJ7ggHaepZjcoVTr4hAREZlVfn4+HnjgAZUPZLiMTQWgqtJe+/btcf/99+ONN96o8piTJ0+iVatWWLduHQYPHlyjFqDmzZsjPT39mm+gNZGur+Ef/gknBzvs+tvNcLIzYO3atRg6dCicnJxg6+R3RS/1ZV1tk57qqrf6sq7mId/fvr6+NQpAmnaBSSGlRSYlJaXCfnks43ZqQt687t27Iy4urtpjWrZsqX6WHFNVAJLxQrJVdW5b+kVsF+iJEG83NQ5oV2IObmrd1CbreS16qi/rapv0VFe91Zd1vT61OZ+mg6CdnZ3Rs2dPrF+/3rRPxvXI4/ItQldTUlKCAwcOIDAwsNpjkpKSkJGRcdVj9Lc6PK8KTURE+qX5LDCZAv/ZZ59h8eLFOHLkCCZNmoS8vDw1K0yMGzeuwiDpWbNmYc2aNapbS6bNP/TQQ2oa/OOPP24aIP3Xv/4V27dvR3x8vApTo0aNQuvWrdX0er0rfz0gTocnIiK90rQLTIwZMwZpaWmYPn06kpOT0a1bN6xatco0tT0xMVHNDDPKyspS0+blWJnhJS1IMoZIptAL6VLbv3+/ClTZ2dkICgpCVFSUGh9UVTeX3tzYumw6/OnMiziVnq91cYiIiPQZgMTUqVPVVhWZzl7e+++/r7bquLm5YfXq1WYvo61wd3ZEn/Cm2BKXjk3H01H5CkpERES2T/MuMGp4xnFAm4+na10UIiIiTTAA6Xl1+PgsFJVoXRoiIqKGxwCkQ62aNUawlxuKLpXieI6d1sUhIiJqcAxAOp0OP/ByK9CRLAYgIiLSHwYgnRrUtiwAHc6243R4IiLSHQYgnbqxta9aEiOj0A7xGZwOT0RE+sIApFONXRzRK9Rb3Zfp8ERERHrCAKRjN7XxVbebjzEAERGRvjAA6djAywFoR3wWLnI+PBER6QgDkI619msEL2eDmg6//WSG1sUhIiJqMAxAOp8O38GrbAbYxthUrYtDRETUYBiAdK699+UAdCxN66IQERE1GAYgnWvraVDT4RMy8nEqPU/r4hARETUIBiCdc3UAerbwUvfZDUZERHrBAES4qW3ZbLCNsewGIyIifWAAItN0eJkJVlDM6fBERGT7GIAIbfwaI9DTFYWXSrGN0+GJiEgHGIBITYcfdHl1+E3sBiMiIh1gACJlYFs/dcuB0EREpAcMQKT0a+0DR/uyleHjOR2eiIhsHAMQKU1cndArrGx1eLYCERGRratTADp9+jSSkpJMj6Ojo/Hss89i/vz55iwbNbBB7S53g/Gq0EREZOPqFIAeeOABbNiwQd1PTk7G0KFDVQh69dVXMWvWLHOXkRqIcSD0thOcDk9ERLatTgHo4MGD6NOnj7q/bNkydOrUCVu3bsXXX3+NRYsWmbuM1EDa+TdBgEfZdHiuDk9ERLasTgGouLgYLi4u6v66detwxx13qPsRERE4d+6ceUtI2kyHZzcYERHZsDoFoI4dO2LevHn4448/sHbtWgwfPlztP3v2LHx8fMxdRmpAvB4QERHpQZ0C0D//+U98+umnGDRoEO6//3507dpV7f/pp59MXWNknfq19lXT4U+m5yExI1/r4hAREdULx7q8SIJPeno6cnJy4O1dNnVaPPHEE3B3dzdn+UiD6fA9Q72x41QmNh5LxbjIMK2LREREZBktQBcvXkRhYaEp/CQkJOCDDz5AbGws/PzKplKTDUyHZzcYERHZqDoFoFGjRuHLL79U97Ozs9G3b1+89957GD16ND755BNzl5E0Gge09UQ6p8MTEZFNqlMA2r17NwYMGKDuf//99/D391etQBKKPvzwQ3OXkRpYREDZdPiC4lJEn8rUujhERESWEYDy8/PRpEkTdX/NmjW46667YG9vjxtuuEEFIbL+6fAD25a1ArEbjIiIbFGdAlDr1q2xfPlytSTG6tWrERUVpfanpqbCw8PD3GUkDbvBZCA0ERGRralTAJo+fTpeeOEFhIWFqWnvkZGRptag7t27m7uMpIF+bS5Ph0/Lw+lMTocnIiLbUqcAdM899yAxMRG7du1SLUBGgwcPxvvvv2/O8pFGPFyd0COUq8MTEZFtqlMAEgEBAaq1R67+bFwZXlqDZDkMsrFuMI4DIiIiG1OnAFRaWqpWfff09ERoaKjavLy88MYbb6jnyDYMalt2PaCtXB2eiIhsTJ2uBP3qq6/iiy++wD/+8Q/069dP7duyZQtef/11FBQU4K233jJ3OUkD7QObwN/DBSk5hdgZn4kBbcpahIiIiHQZgBYvXozPP//ctAq86NKlC4KDgzF58mQGIBubDr9sV5LqBmMAIiIiXXeBZWZmVjnWR/bJc2SLy2JwIDQREek8AMnq7//+978r7Zd90hJEtrU6vIO9HU5wOjwREem9C+ydd97BrbfeinXr1pmuAbRt2zZ1YcRff/3V3GUkDXm6OaFHCy/sjM/CxmNpePiGUK2LREREpE0L0MCBA3Hs2DHceeedajFU2WQ5jEOHDuGrr766/lKRRXaDbWI3GBER6bkFSAQFBVUa7Lxv3z41O2z+/PnmKBtZCBkIPWd1rJoOX3ipBC6ODloXiYiISJsLIZJ+dAzyQLMmLsgvKsHOU1laF4eIiOi6MQBRLVeHZzcYERFZPwYgquXq8FwWg4iIdDYGSAY6X40MhibbNKB1MzUdPi41F4kZ+Wjh4651kYiIiBomAMnaX9d6fty4cXUvDVksT3cn9Alrim0nM7DmcDIeH9BS6yIRERE1TABauHBh3X8SWb1hHf1VAFp1kAGIiIisG8cAUY1FdQxQtzGJWUi7UKh1cYiIiOqMAYhqLMjLDV1CPGEwAGsPp2hdHCIiIusOQB9//DHCwsLg6uqKvn37Ijo6utpjFy1apKZll9/kdeUZDAZMnz4dgYGBcHNzw5AhQ3D8+PEGqIntG3a5FWj1oWSti0JERGS9AWjp0qWYNm0aZsyYgd27d6uFVocNG4bU1OqvN+Ph4YFz586ZtoSEhEprlX344YeYN28eduzYgUaNGqlzFhQUNECN9BGAtp5IR05BsdbFISIiss4ANHfuXEycOBHjx49Hhw4dVGhxd3fHggULqn2NtPoEBASYNn9//wqtPx988AH+/ve/Y9SoUWp1+i+//BJnz57F8uXLG6hWtqu1X2O0atYIxSUGbDjKiyISEZHO1gIzh6KiIsTExOCVV14x7bO3t1ddVrK6fHVyc3MRGhqK0tJS9OjRA2+//TY6duyonjt16hSSk5PVOcpPz5euNTnn2LFjK52vsLBQbUY5OTnqtri4WG22yli32tZxaHs/nEg7hVUHzmFkx7KFUm25vtaIdbVNeqqr3urLuppHbc6paQBKT09HSUlJhRYcIY+PHj1a5WvatWunWoekZef8+fN49913ceONN6qV6ENCQlT4MZ7jynMan7vS7NmzMXPmzEr716xZo1qjbN3atWtrdbx7rvzXEb8fScaKX87ASfN2xPqtrzVjXW2Tnuqqt/qyrtcnPz/fOgJQXURGRqrNSMJP+/bt8emnn+KNN96o0zmlBUrGIZVvAWrevDmioqLUeCNbJUlZfgGHDh0KJyenGr9Ouhm/SdiM5JxCNGnTG7dcXibDVutrjVhX26SnuuqtvqyreRh7cCw+APn6+sLBwQEpKRWnVMtjGdtTE/Lmde/eHXFxceqx8XVyDpkFVv6c3bp1q/IcLi4uaqvq3Lb+i1jXespg6MXbErDuSBqGdQqCNdHL5ypYV9ukp7rqrb6s6/Wpzfk07bxwdnZGz549sX79etM+Gdcjj8u38lyNdKEdOHDAFHbCw8NVCCp/TkmEMhuspuekms8GW3ckBZdKSrUuDhERUa1o3gUmXU+PPPIIevXqhT59+qgZXHl5eWpWmJC1xYKDg9U4HTFr1izccMMNaN26tVp8dc6cOWoa/OOPP26aIfbss8/izTffRJs2bVQgeu211xAUFITRo0drWldb0ie8KbzcnZCVX4yd8VmIbOWjdZGIiIisJwCNGTMGaWlp6sKFMkhZuqlWrVplGsScmJioZoYZZWVlqWnzcqy3t7dqQdq6dauaQm/04osvqhD1xBNPqJDUv39/dc4rL5hIdefoYI8h7f3xfUySuigiAxAREVkTzQOQmDp1qtqqsnHjxgqP33//fbVdjbQCSUuRbFS/3WASgGRZjBm3d1DvOxERkTWwsgnMZEkGtPGFu7MDzmRfxMEzNR95T0REpDUGIKozVycHDGxbNgWea4MREZE1YQCi68LFUYmIyBoxANF1uTnCD472djiemosTaeoS0URERBaPAYiui6ebk2kGGFuBiIjIWjAAkRm7wSpe0ZuIiMhSMQDRdYvq4A+ZAb/vdDaSzxdoXRwiIqJrYgCi6+bn4YoeLbzV/TWH2Q1GRESWjwGIzGJYx7Ird3McEBERWQMGIDLrOKDtJzORnV+kdXGIiIiuigGIzCLUpxEiApqgpNSA9UdStS4OERHRVTEAkdlE8aKIRERkJRiAyOzjgDYfT0N+0SWti0NERFQtBiAymw6BHgjxdkNBcSk2H0vTujhERETVYgAis7Gzs+NFEYmIyCowAJFZGQPQ+iMpKC4p1bo4REREVWIAIrPqGeoN38bOyCm4hO0nM7QuDhERUZUYgMisHOztMLQDL4pIRESWjQGI6m06/JpDKSgtNWhdHCIiokoYgMjsbmzlg8Yujki9UIi9SdlaF4eIiKgSBiAyOxdHB9wc4afusxuMiIgsEQMQ1e/iqAeTYTCwG4yIiCwLAxDVi0Ht/ODsaI/4jHwcS8nVujhEREQVMABRvZAxQP1b+6r77AYjIiJLwwBE9d8NxgBEREQWhgGI6s2Q9v6wtwMOnc3B6cx8rYtDRERkwgBE9cansQt6hzVV99cc5tpgRERkORiAqF79b3FUdoMREZHlYACiehV1eRzQrvhMZOQWal0cIiIihQGI6lWItzs6BXtAVsRYd4TdYEREZBkYgKjeDetg7AZjACIiIsvAAET1blinsgC05Xg6cgsvaV0cIiIiBiCqf238GiPctxGKSkqx4Wiq1sUhIiJiAKL6Z2dnZxoMzdlgRERkCRiAqEEMvzwdfmNsGgovlWhdHCIi0jkGIGoQXUO84O/hosYAbY3L0Lo4RESkcwxA1CDs7e0QZZoNxm4wIiLSFgMQNfhVodceTkGJXBiIiIhIIwxA1GD6tmwKTzcnZOQVISYhS+viEBGRjjEAUYNxcrDH4Ag/dZ/dYEREpCUGIGpQUeUWRzUY2A1GRETaYACiBjWwbTO4OtkjKesiDp3N0bo4RESkUwxA1KDcnB1wU5tm6v4adoMREZFGGICowQ2/vDYYF0clIiKtMABRgxsc4Q9HezvEplxAfHqe1sUhIiIdYgCiBufp7oQbWvqo+5wNRkREWmAAIk0M4+KoRESkIQYg0sTQy8ti7E7MRmpOgdbFISIinWEAIk0EeLqiW3MvdX/NYQ6GJiKihsUARJqvDcZuMCIiamgMQKT5OKBtJzJwPr9Y6+IQEZGOWEQA+vjjjxEWFgZXV1f07dsX0dHRNXrdkiVLYGdnh9GjR1fY/+ijj6r95bfhw4fXU+mprlo2a4w2fo1xqdSA32PZDUZERDoKQEuXLsW0adMwY8YM7N69G127dsWwYcOQmpp61dfFx8fjhRdewIABA6p8XgLPuXPnTNu3335bTzUgs1wU8SADEBER6SgAzZ07FxMnTsT48ePRoUMHzJs3D+7u7liwYEG1rykpKcGDDz6ImTNnomXLllUe4+LigoCAANPm7e1dj7Wg6x0HtOlYGgqKS7QuDhER6YSjlj+8qKgIMTExeOWVV0z77O3tMWTIEGzbtq3a182aNQt+fn6YMGEC/vjjjyqP2bhxozpGgs8tt9yCN998Ez4+ZRffu1JhYaHajHJyyhbpLC4uVputMtZNyzq2beaGYC9XnMkuwIYjyRjS3s+m69tQWFfbpKe66q2+rKt51Oacmgag9PR01Zrj7182GNZIHh89erTK12zZsgVffPEF9u7dW+15pfvrrrvuQnh4OE6cOIG//e1vGDFihApVDg4OlY6fPXu2ak260po1a1RrlK1bu3atpj+/tas9zsAeC9fuRtGpUpuvb0NiXW2Tnuqqt/qyrtcnPz/fOgJQbV24cAEPP/wwPvvsM/j6+lZ73NixY033O3fujC5duqBVq1aqVWjw4MGVjpcWKBmHVL4FqHnz5oiKioKHhwdslSRl+QUcOnQonJycNCuHz6lMbFqwC8dyXRA1bCAcHextur4NgXW1TXqqq97qy7qah7EHx+IDkIQYaZFJSak4AFYey7idK0lrjgx+vv322037SkvLWgwcHR0RGxurgs6VZJyQ/Ky4uLgqA5CMF5LtSvLB2PovoiXUM7K1H5o2ckZmXhH2JF3Aja2rD7e2UN+GxLraJj3VVW/1ZV2vT23Op+kgaGdnZ/Ts2RPr16+vEGjkcWRkZKXjIyIicODAAdX9ZdzuuOMO3Hzzzeq+tNpUJSkpCRkZGQgMDKzX+lDdONjbmcb+zP/jJPYkZqGk1KB1sYiIyIZp3gUmXU+PPPIIevXqhT59+uCDDz5AXl6emhUmxo0bh+DgYDVOR64T1KlTpwqv9/IqW07BuD83N1eN57n77rtVK5K0Gr344oto3bq1ml5Plmlk50As25WEjbFpavNwdURkKx/0b9MMA1r7ItTHXV3PiYiIyCYC0JgxY5CWlobp06cjOTkZ3bp1w6pVq0wDoxMTE9XMsJqSLrX9+/dj8eLFyM7ORlBQkBrL88Ybb1TZzUWWYWDbZphzTxesO5KCrScykFNwCasPpahNhHi7oX9rX/Rv44t+rXzh3chZ6yITEZEV0zwAialTp6qtKjJw+WoWLVpU4bGbmxtWr15t1vJR/ZPWnXt7NVfbpZJSHDhzHluOp+OPuHTVJZaUdRFLdp5WmzQEdQryRL/WvhjQxhc9Q73h6lR5dh8REZFFByCi8mQWWPcW3mr7y+A2yCu8hOhTmfjjeDq2xKXhWEquCkiyzdt0Ai6O9ugT3tTUQtQ+wAP29uwuIyKi6jEAkcVr5OKImyP81CZScgrwZ1y6qYUo7UKhCkey4TfAp5Gzah0yBqIgLzetq0BERBaGAYisjr+HK+7qEaI2g8GgWoS2qECUhh2nMpGRV4Sf9p1Vm2jZrJEaSB3Z0hucXEZERIIBiKx+7FC7gCZqm9A/HEWXSrE7MUu1EEmL0P6kbJxMy1Pb4m0J6OZjj+ElpdDJZTaIiKgaDEBkU5wd7XFDSx+1PR/VDufzi7HtZFkYWrbrNPZm2OPVFYfx7r3dOE6IiEjHNF8Nnqg+ebo7YXinQLx1Z2fMvbcL7GDAD3vOYtYvh1X3GRER6RMDEOnG8I7+eKB12dIpi7bGY+7aY1oXiYiINMIARLrSp5kBM26LUPc/+j1OTaMnIiL9YQAi3Xmobwu8OLyduv+P347iq23xWheJiIgaGAMQ6dLkQa0x5eZW6v5rKw7hh91JWheJiIgaEAMQ6dYLUe3wSGSouv/X7/dj1cFkrYtEREQNhAGIdH0NoRm3d8TdPUJQUmrA09/uweZjaVoXi4iIGgADEOmaXAvon3d3xohOASgqKcUTX+3CzvhMrYtFRET1jAGIdE8WX/3X2O4Y2LYZCopL8djCnTiQdF7rYhERUT1iACK6fAXpeQ/1VKvKXyi8hHELduB4ygWti0VERPWEAYjoMjdnB3zxSC90DfFEVn4xHvx8BxIy8rQuFhER1QMGIKJymrg6YdH4Pmjn3wSpFwpVCDp3/qLWxSIiIjNjACK6gncjZ3w1oQ/CfNyRlHURD32+A+m5hVoXi4iIzIgBiKgKfh6u+M/jfRHo6YoTaXkY90U0zl8s1rpYRERkJgxARNUI8XbH14/3hW9jZxw+l4PxC6ORV3hJ62IREZEZMAARXUXLZo3x1YS+8HB1xO7EbHWdoILiEq2LRURE14kBiOga2gd6YPFjfeDu7IA/4zIw9Zs9KC4phbW7VFKKvaezMW/TCUz5ejc+WHcMSVn5WheLiKhBODbMjyGybt1beOPzR3ph/MKdWHckBS98tw9z7+sGB3s7WFPgOXQ2B9tPZmDbyQzsis9CbvkuvQPAv9Yfx42tfHBvz+YY3ikArk4OWhaZiKjeMAAR1dCNrXzxyUM98MSXMVix96xqEXr7zs5qTTFLVGIADpw5j50J51Xo2Xll4AFU117flj7oEuyJ7acyVAuXcWuywhG3dw3CvT1D0K25l8XWk4ioLhiAiGrhlgh/fDC2m1o49dvo02jk7IhXb21vEeFAFnQ9dLYs7GyNS8f2Ew4o2L6jUuDpE+6DG1o2RWQrH0QEeJhasf6CNjidmY//7k7C9zFJ6hIA3+xIVFsbv8a4t1cIRncPhl8TV41qSERkPgxARLV0W5cg5BeW4MX/7sfnW06piyc+M6SNJoHn8OUuLdmiT2WqZTz+xw5NpIUnvCluaCmhx0eNZ7pat13zpu54dkhbPH1LG3XO72KS8NvBcziemou3fz2Kf66Kxc3tmuHeXs1xS4QfnBw4jJCIrBMDEFEd3Ne7uepOmvXLYby/7hgauTjg8QEt6z3wHDl3eQzPiQxEx2fiQkHFLq0mLtLC0xR9wrxQfOYwHr9nKFxdnGv9s+zt7XBja1+1zRzVEb/sO4fvYk5jT2I21h1JVZtPI2fVIiQtQ9KSRERkTRiAiOrosf7h6rpA7609hjdXHjENlpYZYkWXStWtbIXqvqHC/qIKxxjU/Yr7yu4XyesuP3cs5UK1gcfYwtMhqKyFp7i4GL/+etgsg7Q9XJ3wQN8WaotLvaBahX7YfQZpFwrxxZZTausS4qnGCt3RNRie7k7X/TOJiOobAxDRdZh6S2vVEvTp5pOmEFSfGpsCT1no6RDoAccG7IZq7dcEr4xoj79GtcOmY2n4bleSmhW3P+m82t5YeQTDOgaoMNSvta9VzZIjIn1hACK6DjL4+eUREXBxtMd/d59RX/jOjvZqbIyzg13Z7eXHsslxTlfsl1vny887Odqp+/87h+wrO1eQl1uDB57qSBkGt/dXW0ZuIZbvPYvvdp3G0eQL+HnfWbXJMiJ39wjBPT1DEObbSOsiExFVwABEZIYQNC2qndr0yKexCyb0D8dj/cLUdYaW7TqtLhNw7nwB/r0hTm0yEPv5qHaq9YqIyBJo/09JIrKZINgp2BOzRnXCjr8Nxr8f6I6b2jaDXCFgx6lM3PfpNkxbtleNHSIi0hoDEBGZnVxBWi4X8OVjfbD15Vtwf58WKgjJ4Olb3tuIL7fFq1ltRERaYQAionoV6OmG2Xd1xo+T+6FTsIeayTZ9xSGM+ngL9iRmaV08ItIpBiAiahCynMaKKf3xxqiO6gKNB8/k4K5PtuKVH/YjK69I6+IRkc4wABFRg5FZcg9HhmHDC4PUDDGDAWpJEekWWxKdiFJ2ixFRA2EAIqIG59vYBe/d1xXLnoxEO/8myMovxss/HMDd87aq9cyIiOobAxARaUamxf/ydH/8/db2aOTsoJbauP2jLXj9p0PIKSjWung4n1+M1YeSOVaJyAbxOkBEpCm54KOsoyazxt5ceRi/7D+HRVvj1e2rt0ZgdLdgNcW+oZxIy8Xvar2zFOxKyDLNVusd5o3JN7fGIDW1n1e4JrJ2DEBEZBECPF3x7wd64P4+6XhtxUGcTMvDc0v3YUn0abwxuhPa+jepl58r667tjM/E+iOp+P1oKk6l51V4vmWzRkjKvIid8VkYv3Cnuhr35JtbYUSnQC71QWTFGICIyKLIGmK/PTMAn/9xCh/9flxdRHHkv/5Qi88+M7gNGrlc//+2ZNbZxmNlq9pvjk3DhcL/LTIrS5XIOmuDI/xwS4Q/Wvi4IyWnQC36+vX2BBw+l4Op3+xBuO8xPDWwJe7sHqKWLiEi68IAREQWx8XRAVNubo1R3YIw6+fDWHM4BfM3n8RPe8/itds6YGTngFp1QxkMBhxPzb3cypOCmIQslJ9w5tPIGTdH+GFIez/0b9NMLTpbnr+HK/42sj0mD2qFxVsTsHDrKdVS9NJ/D+CDdccxcUBLjO3THO7O/F8qkbXgXysRWawQb3fMH9cLG46mYsZPh5CYmY8p3+zGgDa+mHlHR7Rs1rja1xZeKkH0qbKurfVHU3A682KF5yMCmmBIe3/c0t4P3UK8YF+D7iwvd2c8M6QNHh8Qjm+jE/HZHyfVmmezfjmsWqse6xeOcZFh8HR3Mkv9iaj+MAARkcWT1pnIVj74ZOMJfLLpBP44no7hH/yBJ25qiSf6h5qOS88tVGFJxvJsPpaGvKIS03PSTXVjq8tdW+39EezlVufySDecDNx+ODJULe8xb9MJJGTk4721x/Dp5pN48IYWaoFYvyau1113IqofDEBEZDXriz03tC3u7B6M138+hI2xaWql+eV7khDRyB4L5+/AvqTz6uKKRs2auFweyyNdW75m76KSrjpZ5+zeniH49WAy/m9DHI4mX8Cnm05i4Z/xuK9XCJ68qRWaN3U3688louvHAEREViXMtxEWPtobqw+lYNbPh5CUXYCkbBmEXHYBRVlvTAYvy3ieTkGeNeraul6ODva4o2sQbu8SqFqfPt4Qh92J2fjP9kR1petRXYMwaVArtKmnmWxEVHsMQERkdWQA9PBOAbiprS/mbYjDlv3HcWe/ThjaMVBNp9eyXINlXFGEn5q9JkFIuut+2HNGbVEd/NXg7q7NvTQrIxGVYQAiIqslXVp/uaUVWhXEYmTvEDg5WcbgYwlCMpVetgNJ5/F/G+Ow6lCyms0mW//WvmpGmYxr4kUVibTBAEREVI86h3jik4d6Ii41Vw2WXr7nDLbEpautW3MvFYSk1YgXVSRqWAxAREQNoLVfY7x7b1c8O6QNPtt8Ekt2nsbe09l44qsYNHFxRO/wpugrW0sfdAryUOOKiKj+MAARETXwtY1mjuqEqbe0wcI/T+HrHYk4f7FYDZ6WTcjCsL3CJAw1Vd1onYM91ZppRGQ+DEBERBqQKfovDo/A81HtcORcDrafzMD2k5mIPpWBnIJL2HQsTW3C3dkBPUO90auFF0pzgKJLpbCQ4U5mJ1ftTrtQqK60fTojFzkFWpeIbJVFBKCPP/4Yc+bMQXJyMrp27YqPPvoIffr0uebrlixZgvvvvx+jRo3C8uXLK/wBzZgxA5999hmys7PRr18/fPLJJ2jTpk0914SIqHZk7E+nYE+1ycUVZfX5o8k52HEyEztOZajZZNn5xWo2mWzyv+1Pj/2OHi280TdcBlo3VbPK5DpJ1kL+H516OeQkZOThVHr+5Vt5nI+LxeUuYGnvgJZdMzAoIkDTMpPt0TwALV26FNOmTcO8efPQt29ffPDBBxg2bBhiY2Ph5+dX7evi4+PxwgsvYMCAAZWee+edd/Dhhx9i8eLFCA8Px2uvvabOefjwYbi68sqsRGTZgahjkKfaZAHY0lIDjqVeUIFo24l0bIlNRm5xKbaeyFCb8SrX3Zt7qe4y6TaTcKR1IJJyVwg5GXlISM9HfEblkHMlGQ8uXYUOdsCpjHxM/Go3/v1ADwzryBBENhSA5s6di4kTJ2L8+PHqsQShlStXYsGCBXj55ZerfE1JSQkefPBBzJw5E3/88Ydq5Sn/LwsJUX//+99Vy5D48ssv4e/vr1qJxo4d20A1IyK6fnIhx4gAD7U90DsYK1eeQdveNyHmdFm3mQQjWQJEWopkw3rA2cEeXZt7qkAkM83cnBzUdHsJVxIu5Jz28tjODjIL3/4qz5Xtt4O9/eXj7Co+zikoNrXcxKfnmQKO3BYUl1ZbLzlviLcbQn0aIdzHvezWtxFCfdxV+JFQl3uxEA98tAb7M+0x+evdeOfuLri7Z0iDvv9kuzQNQEVFRYiJicErr7xi2mdvb48hQ4Zg27Zt1b5u1qxZqnVowoQJKgCVd+rUKdWVJucw8vT0VK1Lcs6qAlBhYaHajHJyctRtcXGx2myVsW62XEe91pd1tU1SRwklYd4uaOMXhLE9g9Q/+qQLaUe8jB/Kws74LKRcKFS3smlJhRwvCTluCG0qIadsC/NxR5Cnmwo5VTKUoLi4BPaGEjzathSbLwZh+b5kPP/dPmTnF2LcDS1ga/T2e1xfda3NOTUNQOnp6ao1R1pnypPHR48erfI1W7ZswRdffIG9e/dW+byEH+M5rjyn8bkrzZ49W7UmXWnNmjVwd7f9NXzWrl0LPdFTfVlX/dTVE8DQxsCQjkBaAXAixw5xOXY4l2+HEgMgS6TJOmmll2/lcanhivtXHHPlrQGVr1VkDwOaugLNXA1odvnW9/JtUxcJQfKFVPaPSmQB+VnA4TjgcA3rKt1gA92SkBlgj83J9nhj5VHE7D+EqGCDCoO2Ru+/x9crPz/ferrAauPChQt4+OGH1eBmX19fs51XWqBkHFL5FqDmzZsjKioKHh4esFWSlOUXcOjQoRZzBd36pKf6sq62Seu6SmuTCkQGQ1moMhjgaG9Xb9csMtZ3WNRQ3OroiI82nMBHG07i19MOCGgeipeHt7WZK2lr/dnaSl2NPTgWH4AkxDg4OCAlJaXCfnkcEFB5sNuJEyfU4Ofbb7/dtK+0tKyP2dHRUQ2cNr5OzhEYGFjhnN26dauyHC4uLmq7knwwtv6LqKd66rG+rKtt0lNdy9f3+WHt4dXIFW/8chgLtiYgr6gUb9/V2aauoq2nz9apHupam/NpemUtZ2dn9OzZE+vXr68QaORxZGRkpeMjIiJw4MAB1f1l3O644w7cfPPN6r602sisLwlB5c8piXDHjh1VnpOIiKzHhP7heOeeLmrA9tJdp/H0t3vUdZGIakvzLjDpenrkkUfQq1cvde0fmcGVl5dnmhU2btw4BAcHq3E6MoW9U6dOFV7v5VW2qnL5/c8++yzefPNNdd0f4zT4oKAgjB49uoFrR0RE5nZfr+Zq+ZCnl+zBygPnkFt4CfMe6gk3Z8u4FpIEsq93JODgmRzc1NYXUR0CLKZs15KaU4Af95zBxtg0dAzywNND2sDD1TZbpDQPQGPGjEFaWhqmT5+uBilLN9WqVatMg5gTExPVzLDaePHFF1WIeuKJJ9QU+f79+6tz8hpARES2YUTnQHzu4oinvopRV8x++Isd+OLR3vB00+7LWsZErT+Sird+PaIuDSD+uzsJjV0cMbJzAO7uEYLeYU3VpQYsSUFxiSr39zGn1XspA+LFtpMZ+GnfWcy4vaMqv62Mt7KYACSmTp2qtqps3Ljxqq9dtGhRpX3yIclUedmIiMg2DWzbDP95vA8eXbgTuxKycP/87fhyQh/4Nq48prO+ydW73/zlCLbEydW6ocpwW5dArD+agtOZF7FsV5La5NpHd/UIwV3dgxHm2whahrV9SedV6Pl53zm1Hp1Rr1BvDOngj6U7T6sgN+Wb3RjUrhneGNUJzZvazsxoiwhAREREddEztCmWPHEDHlkQjcPncnDfvG34z+N9EeTl1iA/PyO3EHPXHsO30Ymq5UQuQjlhQDgmD2qFJq5OmH5bBxXO/huTpLrrkrIu4sP1x9UmQUPC0K1dAuHeQN/GKZe7uL6PSUJcaq5pf6Cnq2qhuqtHMFo2a6z2PXpjGP5v4wnM23hCdYkNfX8Tnh7cBhMHtLSJxXkZgIiIyKrJsiHLnozEQ5/vwMn0PNw7bxu+mtDH9EVeX+N8Fm+Nx4e/H8eFgktqn3QTvTKifYVWEunu6hPeVG2v39ERaw4n47+7z2DL8TQVjGR7/edDGBLRDCGX7BBVYv6FbqWLa92RFBV6Npfr4nJ1ssfwjgG4p2dzRLbyqTSbTpZTmTa0LUZ1C8LffzyousTeWRWL5XvO4K07O6vuPGvGAERERFZPws53k27Ew5dD0H2fbsOXj/VFhyAPs3cdrZNxPisPIz6j7KJ7MlhYWnr6tvS56mtlIPSobsFqk5YYCRIyRuhYSi5+PSiXg3HAD+9uxuhuwapl6HrKLuXcezpbhZ6f951FzuWQJnqHeeOeniEY2TlQtVJdS6tmjfHNxL6q5ejNlUdUeSVkjunVHK+MjICXuzOsEQMQERHZhGAvNyx7KhLjvijrDhszfxsWje+tusnM4ci5HLy58jD+jMswjfN5cVg7tT5Zba9F5O/hiicHtsITN7XEobM5WLYzEf/dlYD03CJ8vuWU2toHeuDuHmWBqVmTmo1rSj5v7OI6jRNpZQOxRZB0cfWULq4QteZabcnYWnntLRF++MdvR7Fk52l1GYK1R1Lw6sj2quvM2gZJMwAREZHNkFDy7RM3YMKisoHRD30ejfnjemJAm2Z1Pmf65XE+S4zjfBzt8Xj/cEy+ubWa4XU9JDR0CvZEO78IdDOchHurXlixP1nNyioLXDmY/dtRNeBbQsaQ9v6qa+rKLq41h8u6uKRrrXwX18hOgSr4RLb0McvsMy93Z/zj8qK0r/54QLUGyRpt8rPfvLOTai2yFgxARERkU2Qq/FcT+uLJ/8SoMS+PLdqJD8d2V1Pna6PwUoka5/PR+jhcKCzrQrq1cyBeHhFRL7OhZFzx4PZ+GN4lGNn5Rfh5/zk1eFq6sn4/mqq2Jq6OuK1LEO7pWdbiYuziMo5DEn3CmqourhGdA2rUxVUXMv7nl78MwOdbTqoB3TI+aMQHf+CpQa3UAPArQ5olYgAiIiKbI+NtPh/XC88u3YNfDySrqdzSciEXUazJ+Jm1h1PU9XwSLo/z6RQs43w6qsHMDUFaWh6+IVRtJ9Jy8cPuJPy4+wzOni9QM85ku7L7T7rLpJuqoabXOzvaY/Kg1ri9SxBeW3FQzRSTMCSBTKbM929jvjU76wMDEBER2ST5gv7o/h5o4nJAjVd58fv9yC24hMf6h1f7Gul2krXGtp4oG+cjY2/UOJ8eIZpdwFC6lf46LALPD22H7Scz1Cyy3w6eUwvTSiuPtPbcEG6eLq66kNawhY/2xm8Hk/H6T4fUtYMe+mIHRncLwqu3dqjx+KWGxgBEREQ2SwYn/+PuzqrrSAYWz/rlMHIKivHM4DYVBu3KOJ/31hzD0p3/G+czcUA4Jg26/nE+5iIB58bWvmqbfVdntU/KaQns7OzUrDJp9XlvdSy+3J6A5XvPqm67l0e0x9jezS3uCtiW8akSERHV45fzq7e2V2OD3lt7DB+sO66ufPzarR1QXFqKRX/G49+/lxvn0yUQLw+vn3E+5mIpwedKsm7YzFGd1CDpv/14QK2HJrcyK+3tuzojIsC8lyW4HgxARESkixD0l8FtVEvQ6z8fxsI/49VVmY+lXDCN8+kc7Inpt3ew+gv8WYIuIV5YPrkfvtyWgPfWxGJ3YjZu/XBL2ey5gWGwBAxARESkG4/2C1czo17873410Fn4yTif4RFqfS5L66axZo4O9mq8lYxTmvnTYaw6lIxPN5/EL/vPYmSAHUZqXT6Nfz4REVGDku4ZaQmSa/vIdXUmDWqFRhYyzscWBXq6Yd7DPbH+SAqmrziEM9kX8Vm2A3J/OozZd3fVrFz8xImISHeiOgaojRrO4Pb+as2xuWtisWDLKbUkh5YYgIiIiKhBuDs74qVhbRGQG4fbOmsbQC1zGDkRERHZrGZuZQPTtcQARERERLrDAERERES6wwBEREREusMARERERLrDAERERES6wwBEREREusMARERERLrDAERERES6wwBEREREusMARERERLrDAERERES6wwBEREREusMARERERLrjqHUBLJHBYFC3OTk5sGXFxcXIz89X9XRycoKt01N9WVfbpKe66q2+rKt5GL+3jd/jV8MAVIULFy6o2+bNm2tdFCIiIqrD97inp+dVj7Ez1CQm6UxpaSnOnj2LJk2awM7ODrZKkrKEvNOnT8PDwwO2Tk/1ZV1tk57qqrf6sq7mIZFGwk9QUBDs7a8+yoctQFWQNy0kJAR6Ib+Atv4Hp9f6sq62SU911Vt9Wdfrd62WHyMOgiYiIiLdYQAiIiIi3WEA0jEXFxfMmDFD3eqBnurLutomPdVVb/VlXRseB0ETERGR7rAFiIiIiHSHAYiIiIh0hwGIiIiIdIcBiIiIiHSHAchGzZ49G71791ZXs/bz88Po0aMRGxt71dcsWrRIXfm6/Obq6gpr8Prrr1cqe0RExFVf891336ljpI6dO3fGr7/+CmsQFhZWqa6yTZkyxeo/182bN+P2229XV3GVci5fvrzC8zJnY/r06QgMDISbmxuGDBmC48ePX/O8H3/8sXrfpN59+/ZFdHQ0LL2+sl7SSy+9pH43GzVqpI4ZN26cukq9uf8WLOGzffTRRyuVe/jw4Vb52V6rrlX9/co2Z84cq/tcZ9fgu6agoED9/8nHxweNGzfG3XffjZSUlKuet65/67XBAGSjNm3apH7htm/fjrVr16r/mUZFRSEvL++qr5Orcp47d860JSQkwFp07NixQtm3bNlS7bFbt27F/fffjwkTJmDPnj3qj1a2gwcPwtLt3LmzQj3l8xX33nuv1X+u8vvZtWtX9aVWlXfeeQcffvgh5s2bhx07dqhgMGzYMPU/2OosXboU06ZNU9Nud+/erc4vr0lNTYUl11cWi5Tyvvbaa+r2hx9+UF8sd9xxh1n/FizlsxUSeMqX+9tvv73qOS31s71WXcvXUbYFCxaoQCPBwNo+1001+K557rnn8PPPP6t/dMrxEuLvuuuuq563Ln/rtSbT4Mn2paamyuUODJs2bar2mIULFxo8PT0N1mjGjBmGrl271vj4++67z3DrrbdW2Ne3b1/Dk08+abA2zzzzjKFVq1aG0tJSm/pc5ff1xx9/ND2W+gUEBBjmzJlj2pednW1wcXExfPvtt9Wep0+fPoYpU6aYHpeUlBiCgoIMs2fPNlhyfasSHR2tjktISDDb34Kl1PWRRx4xjBo1qlbnsYbPtiafq9T7lltuueox1vC5VvVdI3+jTk5Ohu+++85gdOTIEXXMtm3bDFWp6996bbEFSCfOnz+vbps2bXrV43JzcxEaGqoWqhs1ahQOHToEayHNo9Lk3LJlSzz44INITEys9tht27apJtXy5F8Xst+aFBUV4T//+Q8ee+yxqy7ca82fq9GpU6eQnJxc4XOTNX+k26O6z03en5iYmAqvkbX+5LG1fdbGv2P5nL28vMz2t2BJNm7cqLpR2rVrh0mTJiEjI6PaY23ls5WuoJUrV6rW6Guxhs/1/BXfNfIZSatQ+c9Juu5atGhR7edUl7/1umAA0snq9s8++yz69euHTp06VXuc/E9HmmJXrFihvlTldTfeeCOSkpJg6eQPQ8a6rFq1Cp988on6AxowYIBaFbgq8sfl7+9fYZ88lv3WRMYWZGdnq/ETtvi5lmf8bGrzuaWnp6OkpMQmPmtp+pcxQdJ1e7UFJGv7t2AppPvryy+/xPr16/HPf/5TdZWMGDFCfX62/NkuXrxYjZ+5VpeQNXyupVV818hn4ezsXCm0X+1zqsvfel1wNXgdkP5ZGdtyrf7iyMhItRnJl2T79u3x6aef4o033oAlk/9RGnXp0kX9z0JaPJYtW1ajf1lZqy+++ELVXf5VaIufK5WRf0Hfd999amCofPnZ4t/C2LFjTfdl4LeUvVWrVqpVaPDgwbBV8o8Tac251sQEa/hcp9Twu8ZSsAXIxk2dOhW//PILNmzYgJCQkFq91snJCd27d0dcXBysjfxro23bttWWPSAgoNIsBHks+62FDGRet24dHn/8cV18rsbPpjafm6+vLxwcHKz6szaGH/m8ZZDp1Vp/6vK3YKmkm0c+v+rKbQuf7R9//KEGttf2b9gSP9ep1XzXyGch3ZXSUl3Tz6kuf+t1wQBko+RfivIL+eOPP+L3339HeHh4rc8hzcsHDhxQ0xCtjYx5OXHiRLVllxYRaWovT75cyreUWLqFCxeq8RK33nqrLj5X+R2W//mV/9xycnLUDJHqPjdpeu/Zs2eF10gzvTy2hs/aGH5k7IeEXZlGbO6/BUslXbQyBqi6clv7Z2tswZU6yIwxa/1cDdf4rpH6yT+6yn9OEvpk/FJ1n1Nd/tbrWniyQZMmTVIzfzZu3Gg4d+6cacvPzzcd8/DDDxtefvll0+OZM2caVq9ebThx4oQhJibGMHbsWIOrq6vh0KFDBkv3/PPPq7qeOnXK8OeffxqGDBli8PX1VTMSqqqrHOPo6Gh499131YwEmWEhMxUOHDhgsAYy26VFixaGl156qdJz1vy5XrhwwbBnzx61yf+e5s6dq+4bZz394x//MHh5eRlWrFhh2L9/v5o9Ex4ebrh48aLpHDKb5qOPPjI9XrJkiZo9smjRIsPhw4cNTzzxhDpHcnKywZLrW1RUZLjjjjsMISEhhr1791b4Oy4sLKy2vtf6W7DEuspzL7zwgpoVJOVet26doUePHoY2bdoYCgoKrO6zvdbvsTh//rzB3d3d8Mknn1R5Dmv5XCfV4LvmqaeeUv+/+v333w27du0yREZGqq28du3aGX744QfT45r8rV8vBiAbJX90VW0yJdpo4MCBauqp0bPPPqt+SZ2dnQ3+/v6GkSNHGnbv3m2wBmPGjDEEBgaqsgcHB6vHcXFx1dZVLFu2zNC2bVv1mo4dOxpWrlxpsBYSaOTzjI2NrfScNX+uGzZsqPL31lgfmR772muvqXrIF9/gwYMrvQehoaEq0JYnXyTG90CmTm/fvt1g6fWVL7rq/o7lddXV91p/C5ZYV/myjIqKMjRr1kz9Q0TqNHHixEpBxlo+22v9HotPP/3U4ObmpqZ3V8VaPlfU4LtGQsvkyZMN3t7eKvTdeeedKiRdeZ7yr6nJ3/r1srv8g4mIiIh0g2OAiIiISHcYgIiIiEh3GICIiIhIdxiAiIiISHcYgIiIiEh3GICIiIhIdxiAiIiISHcYgIiIasDOzg7Lly/XuhhEZCYMQERk8R599FEVQK7chg8frnXRiMhKOWpdACKimpCwIwvAlufi4qJZeYjIurEFiIisgoQdWSG6/Obt7a2ek9agTz75BCNGjICbmxtatmyJ77//vsLrDxw4gFtuuUU9L6uqP/HEE2pF7fIWLFiAjh07qp8lq2zLKtflpaen484774S7uzvatGmDn376qQFqTkT1gQGIiGzCa6+9hrvvvhv79u3Dgw8+iLFjx+LIkSPquby8PAwbNkwFpp07d+K7777DunXrKgQcCVBTpkxRwUjCkoSb1q1bV/gZM2fOxH333Yf9+/dj5MiR6udkZmY2eF2JyAzMurQqEVE9kFW0HRwcDI0aNaqwvfXWW+p5+V/ZU089VeE1ffv2NUyaNEndnz9/vlqJOjc31/T8ypUrDfb29qYVx4OCggyvvvpqtWWQn/H3v//d9FjOJft+++03s9eXiOofxwARkVW4+eabVStNeU2bNjXdj4yMrPCcPN67d6+6Ly1BXbt2RaNGjUzP9+vXD6WlpYiNjVVdaGfPnsXgwYOvWoYuXbqY7su5PDw8kJqaet11I6KGxwBERFZBAseVXVLmIuOCasLJyanCYwlOEqKIyPpwDBAR2YTt27dXety+fXt1X25lbJCMBTL6888/YW9vj3bt2qFJkyYICwvD+vXrG7zcRKQNtgARkVUoLCxEcnJyhX2Ojo7w9fVV92Vgc69evdC/f398/fXXiI6OxhdffKGek8HKM2bMwCOPPILXX38daWlp+Mtf/oKHH34Y/v7+6hjZ/9RTT8HPz0/NJrtw4YIKSXIcEdkeBiAisgqrVq1SU9PLk9abo0ePmmZoLVmyBJMnT1bHffvtt+jQoYN6Tqatr169Gs888wx69+6tHsuMsblz55rOJeGooKAA77//Pl544QUVrO65554GriURNRQ7GQndYD+NiKgeyFicH3/8EaNHj9a6KERkJTgGiIiIiHSHAYiIiIh0h2OAiMjqsSefiGqLLUBERESkOwxAREREpDsMQERERKQ7DEBERESkOwxAREREpDsMQERERKQ7DEBERESkOwxAREREpDsMQERERKQ7/w9ndWWS48fcEwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def train_model(train_loader, num_epochs, learning_rate):\n",
        "  # we have provided the loss and optimizer below\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  train_losses = []\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "      total_loss = 0\n",
        "      # TODO: Compute the Gradient and Loss by iterating train_loader\n",
        "      for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device).unsqueeze(1)  # reshape to (batch_size, 1)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "      avg_loss = total_loss / len(train_loader)\n",
        "      train_losses.append(avg_loss)\n",
        "      # TODO: Print and store loss at each epoch\n",
        "      print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "  return train_losses\n",
        "\n",
        "num_epochs = 20\n",
        "learning_rate = 0.001\n",
        "train_losses = train_model(train_loader, num_epochs, learning_rate)\n",
        "\n",
        "# TODO: Plot the Training Loss Curve by (Epoch # on x-axis and loss on y-axis)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "krHbZGHlV5VV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 81.56%\n"
          ]
        }
      ],
      "source": [
        "def test_model():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # When we are doing inference on a model, we do not need to keep track of gradients\n",
        "  # torch.no_grad() indicates to pytorch to not store gradients for more efficent inference\n",
        "  with torch.no_grad():  # No gradient tracking for evaluation\n",
        "    # TODO: Iterate through test_loader and perform a forward pass to compute predictions\n",
        "    for inputs, labels in test_loader:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device).unsqueeze(1)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      predicted = (outputs >= 0.5).float()  # Apply threshold\n",
        "\n",
        "      correct += (predicted == labels).sum().item()\n",
        "      total += labels.size(0)\n",
        "  print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
        "test_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC1Ac-rR4TdZ"
      },
      "source": [
        "### Section 3.5: Hyperparameter Tuning\n",
        "This section is open-ended. We want you to experiment with different setting for training such as the learning rate, using a different optimizer, and using different MLP architecture. Report how you went about hyper-paramater tuning and provide the code with comments. Then provide a table with settings that you experimented with. The table should present 5 different setting with which you trained the architecture. Finally, write up a brief analysis on your findings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-oHqFfJDWCkK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[82.12290502793296,\n",
              " 81.56424581005587,\n",
              " 81.56424581005587,\n",
              " 77.09497206703911,\n",
              " 82.68156424581005]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TODO: Hyper parameter code\n",
        "def run_experiment(hidden_layers=[64, 32], lr=0.001, optimizer_type='adam', batch_size=32, num_epochs=20):\n",
        "    # Build model dynamically based on hidden_layers\n",
        "    layers = []\n",
        "    input_size = 7\n",
        "    for hidden_size in hidden_layers:\n",
        "        layers.append(nn.Linear(input_size, hidden_size))\n",
        "        layers.append(nn.ReLU())\n",
        "        input_size = hidden_size\n",
        "    layers.append(nn.Linear(input_size, 1))\n",
        "    layers.append(nn.Sigmoid())\n",
        "\n",
        "    model = nn.Sequential(*layers)\n",
        "\n",
        "    # Dataset and DataLoader\n",
        "    train_dataset = TitanicDataset(X_train, y_train)\n",
        "    test_dataset = TitanicDataset(X_test, y_test)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    criterion = nn.BCELoss()\n",
        "    if optimizer_type == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    elif optimizer_type == 'sgd':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported optimizer\")\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        for inputs, labels in train_loader:\n",
        "            labels = labels.unsqueeze(1)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            labels = labels.unsqueeze(1)\n",
        "            preds = (model(inputs) >= 0.5).float()\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "acc1 = run_experiment(hidden_layers=[64, 32], lr=0.001, optimizer_type='adam', batch_size=32)\n",
        "acc2 = run_experiment(hidden_layers=[128, 64], lr=0.001, optimizer_type='adam', batch_size=32)\n",
        "acc3 = run_experiment(hidden_layers=[64, 32, 16], lr=0.0005, optimizer_type='adam', batch_size=32)\n",
        "acc4 = run_experiment(hidden_layers=[64, 32], lr=0.01, optimizer_type='sgd', batch_size=32)\n",
        "acc5 = run_experiment(hidden_layers=[64, 32], lr=0.001, optimizer_type='adam', batch_size=64)\n",
        "[acc1, acc2, acc3, acc4, acc5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vaKzcze5Nru"
      },
      "source": [
        "Please explain your hyper-parameter tuning:\n",
        "To perform hyperparameter tuning, I wrote a reusable experiment function that allowed me to change various aspects of the model such as hidden layer sizes, learning rate, optimizer, and batch size. I kept the training epochs fixed at 20 for consistency and changed only one or two parameters at a time so I could clearly see the impact of each. My goal was to understand how these parameters affected accuracy on the Titanic dataset. I began with the baseline model from Section 3.3 and incrementally modified the architecture and training configuration across five different trials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoZ329QS5g3H"
      },
      "source": [
        "Please provide a table with 5 settings:\n",
        "\n",
        "| Trial | Hidden Layer Sizes | Learning Rate | Optimizer | Batch Size | Epochs | Test Accuracy |\n",
        "|-------|--------------------|---------------|-----------|------------|--------|----------------|\n",
        "| 1     | [64, 32]           | 0.001         | Adam      | 32         | 20     | 82.68%         |\n",
        "| 2     | [128, 64]          | 0.001         | Adam      | 32         | 20     | 81.01%         |\n",
        "| 3     | [64, 32, 16]       | 0.0005        | Adam      | 32         | 20     | 79.33%         |\n",
        "| 4     | [64, 32]           | 0.01          | SGD       | 32         | 20     | 78.77%         |\n",
        "| 5     | [64, 32]           | 0.001         | Adam      | 64         | 20     | 81.01%         |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNz-Mq_K5pSq"
      },
      "source": [
        "Please provide your analysis here:\n",
        "The best performance came from the baseline architecture ([64, 32]) with Adam and a learning rate of 0.001 (Trial 1), achieving 82.68% accuracy. Interestingly, increasing the hidden layer sizes (Trial 2) did not improve performance — in fact, it slightly reduced accuracy. Adding a third layer and lowering the learning rate in Trial 3 further decreased performance, possibly due to overfitting or under-training with fewer updates. Trial 4, which used SGD instead of Adam, performed the worst at 78.77%, confirming that Adam was more effective for this problem. Increasing the batch size to 64 (Trial 5) also slightly hurt performance, potentially due to less frequent gradient updates. Overall, the simpler baseline architecture with Adam and a moderate learning rate remained the most reliable. What I will say though, is that due to the relatively small size of the dataset, the percentages tend to vary. This is expected, but the trends could vary depending on those factors. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
